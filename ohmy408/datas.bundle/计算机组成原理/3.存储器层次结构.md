# 3 存储器层次结构

## 导航目录

1. [存储器基本概念](#1-存储器基本概念)
2. [存储器层次结构原理](#2-存储器层次结构原理)
3. [缓存存储器](#3-缓存存储器)
4. [主存储器系统](#4-主存储器系统)
5. [虚拟存储器](#5-虚拟存储器)
6. [存储器性能分析](#6-存储器性能分析)
7. [典型例题](#7-典型例题)
 
## 1. 存储器基本概念

### 1.1 存储器的分类

> **定义1.1（存储器）**
> 
> 存储器是计算机系统中用来存放程序和数据的部件，是计算机的重要组成部分。

#### 1.1.1 按存储介质分类

**半导体存储器**：
- 集成度高、体积小、功耗低
- 存取速度快、可靠性高
- 易失性（需要电源维持数据）

**磁性存储器**：
- 存储容量大、成本低
- 非易失性（断电后数据保持） 
- 存取速度相对较慢

**光存储器**：
- 存储密度高、成本低
- 非易失性、可移动性好
- 主要用于大容量数据归档

#### 1.1.2 按存取方式分类

**随机存取存储器(RAM)**：
- 任意位置的存取时间相等
- 支持读写操作
- 分为SRAM和DRAM

**只读存储器(ROM)**：
- 只能读取，不能写入（或写入困难）
- 非易失性存储
- 用于存储固化程序

**串行存取存储器**：
- 按顺序存取数据
- 存取时间与数据位置有关
- 如磁带存储器

### 1.2 存储器性能指标

#### 1.2.1 存储容量

> **定义1.2（存储容量）**
> 
> 存储容量是存储器能够存储的二进制信息量，通常以字节(B)、千字节(KB)、兆字节(MB)、吉字节(GB)为单位。

**容量计算公式**：
$$存储容量 = 存储单元数 \times 存储字长$$

其中：
- 存储单元数：存储器中存储单元的个数
- 存储字长：每个存储单元存储的二进制位数

#### 1.2.2 存取时间

> **定义1.3（存取时间）**
> 
> 存取时间是从启动一次存储器操作到完成该操作所需的时间。

**读取时间**$T_r$：从地址有效到数据有效的时间
**写入时间**$T_w$：从地址、数据有效到写入完成的时间

#### 1.2.3 存储器带宽

> **定义1.4（存储器带宽）**
> 
> 存储器带宽是单位时间内存储器与CPU之间交换的信息量。

**带宽计算公式**：
$$带宽 = \frac{数据位宽}{存取周期}$$

---

## 2. 存储器层次结构原理

### 2.1 程序访问的局部性原理

> **原理2.1（局部性原理）**
> 
> 程序在执行过程中，对存储器的访问往往不是随机的，而是呈现出局部性特征。

#### 2.1.1 时间局部性

**概念**：最近被访问的存储位置很可能在不久的将来再次被访问。

**产生原因**：
- 程序中的循环结构
- 子程序的重复调用
- 对数组和变量的重复引用

#### 2.1.2 空间局部性

**概念**：最近被访问位置附近的存储位置很可能在不久的将来被访问。

**产生原因**：
- 程序的顺序执行特性
- 数组元素的连续访问
- 相关数据的聚集存放

### 2.2 存储器层次结构

> **定义2.1（存储器层次结构）**
> 
> 存储器层次结构是由不同速度、容量和成本的存储器组成的多级存储系统。

#### 2.2.1 典型层次结构

graph LR
    A["CPU寄存器<br/><span style='font-size: smaller; color: #555;'>最快 / 最小 / 最贵</span>"] <--> B["Cache<br/><span style='font-size: smaller; color: #555;'>较快 / 较小 / 较贵</span>"]
    B <--> C["主存储器<br/><span style='font-size: smaller; color: #555;'>较慢 / 较大 / 较便宜</span>"]
    C <--> D["辅助存储器<br/><span style='font-size: smaller; color: #555;'>最慢 / 最大 / 最便宜</span>"]

#### 2.2.2 层次存储的访问特性

**包含性**：第i级的内容是第i+1级内容的子集
**一致性**：同一数据在各级存储器中保持一致
**替换性**：高速存储器满时，需要替换数据到低速存储器

### 2.3 存储器层次的性能分析

> **例题2.1**：某计算机系统的Cache命中率为95%，Cache存取时间为10ns，主存存取时间为100ns。计算平均存取时间。

**解析**：

平均存取时间的计算公式：
$$T_{avg} = H \times T_c + (1-H) \times (T_c + T_m)$$

其中：
-$H$ = 0.95（命中率）
-$T_c$ = 10ns（Cache存取时间）
-$T_m$ = 100ns（主存存取时间）

计算过程：
```
T_avg = 0.95 × 10 + (1-0.95) × (10 + 100)
      = 0.95 × 10 + 0.05 × 110
      = 9.5 + 5.5
      = 15ns
```

**答案**：平均存取时间为15ns。

---

## 3. 缓存存储器

### 3.1 缓存的基本概念

> **定义3.1（缓存存储器）**
> 
> 缓存存储器是位于CPU和主存储器之间的高速小容量存储器，用于存放当前最活跃的程序和数据。

#### 3.1.1 缓存的工作原理

**命中(Hit)**：CPU要访问的数据在Cache中找到
**未命中(Miss)**：CPU要访问的数据在Cache中没有找到

**命中率(Hit Rate)**：
$$H = \frac{命中次数}{总访问次数}$$

**未命中率(Miss Rate)**：
$$M = 1 - H = \frac{未命中次数}{总访问次数}$$

### 3.2 缓存的映射方式

缓存映射解决了主存地址到缓存地址的转换问题，主要有三种方式：直接映射、全相联映射和组相联映射。

#### 3.2.1 直接映射

> **定义3.2（直接映射）**
> 
> 主存储器中的每个块只能映射到缓存中的唯一指定位置。

**映射关系**：
`缓存行号 = 主存块号 mod 缓存总行数`

**地址结构**：
主存地址被划分为三个字段：标记(Tag)、索引(Index)和块内偏移(Offset)。
```
┌─────────────┬───────────────┬──────────────────┐
│   标记(Tag)   │  索引(Index)  │ 块内偏移(Offset) │
└─────────────┴───────────────┴──────────────────┘
```

**特点**：
- 硬件实现简单，成本低。
- 冲突概率高，命中率相对较低。
- 不需要替换算法。

> **例题3.1**：某系统主存容量为1MB，分为1024个块，每块1KB；Cache容量为8KB，分为8个块。采用直接映射方式，求主存第100块映射到Cache的哪一块？

**解析**：
```
Cache块数 = 8KB ÷ 1KB = 8块
主存块号 = 100
Cache块号 = 100 mod 8 = 4

因此主存第100块映射到Cache第4块
```

**答案**：主存第100块映射到Cache第4块。

#### 3.2.2 全相联映射

> **定义3.3（全相联映射）**
> 
> 主存储器中的任意一个块可以映射到缓存中的任意一个位置。

**地址结构**：
主存地址被划分为两个字段：标记(Tag)和块内偏移(Offset)。
```
┌─────────────────┬──────────────────┐
│   标记(Tag)     │ 块内偏移(Offset) │
└─────────────────┴──────────────────┘
```

**特点**：
- 命中率高，冲突少
- 硬件实现复杂，成本高
- 需要复杂的替换算法
- 适用于小容量高速缓存

**查找过程**：需要同时比较所有标记位，使用相联存储器实现

#### 3.2.3 组相联映射

> **定义3.4（组相联映射）**
> 
> 组相联映射是直接映射和全相联映射的折中方案，将缓存分为若干组，主存块可以映射到指定组内的任意位置。

**映射关系**：
```
组号 = 主存块号 mod 组数
```

**地址结构**：
主存地址被划分为三个字段：标记(Tag)、组索引(Set Index)和块内偏移(Offset)。
```
┌─────────────┬─────────────────┬──────────────────┐
│   标记(Tag)   │ 组索引(Set Index) │ 块内偏移(Offset) │
└─────────────┴─────────────────┴──────────────────┘
```

**N路组相联**：每组包含N个缓存行
- 2路组相联：每组2个缓存行
- 4路组相联：每组4个缓存行
- 8路组相联：每组8个缓存行

> **例题3.2**：某Cache采用4路组相联映射，Cache容量32KB，块大小64B。主存地址32位，求地址字段的划分。

**解析**：
```
Cache容量 = 32KB = 32 × 1024 = 32768B
块大小 = 64B
总块数 = 32768 ÷ 64 = 512块
4路组相联，组数 = 512 ÷ 4 = 128组

块内偏移位数 = log₂(64) = 6位
组索引位数 = log₂(128) = 7位
标记位数 = 32 - 6 - 7 = 19位
```

**答案**：标记19位，组索引7位，块内偏移6位。

#### 3.2.4 映射方式比较

| 映射方式 | 冲突概率 | 硬件复杂度 | 命中率 | 替换算法 |
|----------|----------|------------|--------|----------|
| 直接映射 | 高       | 低         | 低     | 不需要   |
| 全相联   | 低       | 高         | 高     | 复杂     |
| 组相联   | 中等     | 中等       | 中等   | 相对简单 |

### 3.3 缓存替换算法

当缓存满时，需要选择合适的缓存行进行替换。常用的替换算法包括：

#### 3.3.1 先进先出(FIFO)

> **定义3.5（FIFO替换算法）**
> 
> 先进先出算法总是替换最早进入缓存的块。

**实现方法**：
- 为每个缓存行维护一个时间戳
- 替换时选择时间戳最小的缓存行
- 硬件实现简单，但命中率不高

#### 3.3.2 最近最少使用(LRU)

> **定义3.6（LRU替换算法）**
> 
> 最近最少使用算法基于局部性原理，替换最近最少被访问的块。

**实现方法**：
1. **计数器法**：为每个缓存行维护访问计数器
2. **堆栈法**：维护一个访问顺序堆栈
3. **矩阵法**：使用 $n \times n$ 矩阵记录访问顺序

**LRU近似算法**：
- **时钟算法**：使用访问位实现近似LRU
- **二次机会算法**：结合访问位和修改位

> **例题3.3**：某4路组相联Cache，采用LRU替换算法。当前组内4个块的LRU顺序为：块0(最新) → 块1 → 块2 → 块3(最旧)。现在访问块2，求新的LRU顺序。

**解析**：
访问块2后，块2变为最新使用，其他块的相对顺序保持不变：
```
原顺序：块0 → 块1 → 块2 → 块3
新顺序：块2 → 块0 → 块1 → 块3
```

**答案**：块2(最新) → 块0 → 块1 → 块3(最旧)。

#### 3.3.3 最不经常使用(LFU)

> **定义3.7（LFU替换算法）**
> 
> 最不经常使用算法替换访问频率最低的块。

**实现特点**：
- 需要维护访问频率计数器
- 对程序的访问模式变化适应性差
- 硬件开销较大

#### 3.3.4 随机替换(Random)

**特点**：
- 实现最简单，硬件开销最小
- 性能不可预测
- 在某些情况下性能接近LRU

### 3.4 缓存写策略

缓存写操作比读操作复杂，需要考虑缓存与主存的一致性问题。

#### 3.4.1 写命中策略

**写直达(Write Through)**：

> **定义3.8（写直达策略）**
> 
> 写操作同时更新缓存和主存，保证缓存与主存的一致性。

**特点**：
- 实现简单，一致性好
- 写操作速度慢，总线流量大
- 通常使用写缓冲器提高性能

**写回(Write Back)**：

> **定义3.9（写回策略）**
> 
> 写操作只更新缓存，块被替换时才写回主存。

**实现要求**：
- 需要脏位(Dirty Bit)标记块是否被修改
- 替换时检查脏位，决定是否写回
- 写操作速度快，但一致性维护复杂

#### 3.4.2 写未命中策略

**写分配(Write Allocate)**：
- 将包含写地址的块调入缓存，然后在缓存中执行写操作
- 通常与写回策略配合使用

**写不分配(Write Non-allocate)**：
- 直接写入主存，不将块调入缓存
- 通常与写直达策略配合使用

#### 3.4.3 写策略组合

| 写命中策略 | 写未命中策略 | 特点 |
|------------|--------------|------|
| 写直达     | 写不分配     | 简单一致，性能较低 |
| 写回       | 写分配       | 性能较高，复杂度高 |

### 3.5 缓存性能分析

#### 3.5.1 性能指标

**平均访问时间(AAT)**：
$$AAT = H \times T_{cache} + (1-H) \times (T_{cache} + T_{miss\_penalty})$$

其中：
- $H$：命中率
- $T_{cache}$：缓存访问时间
- $T_{miss\_penalty}$：缺失惩罚时间

**有效访问时间(EAT)**：
$$EAT = T_{cache} + (1-H) \times T_{miss\_penalty}$$

**缓存性能提升比**：
$$Speedup = \frac{T_{no\_cache}}{AAT}$$

> **例题3.4**：某系统Cache命中率90%，Cache访问时间2ns，主存访问时间20ns，无Cache时访问时间20ns。计算使用Cache后的性能提升比。

**解析**：
```
AAT = 0.9 × 2 + (1-0.9) × (2 + 20) = 1.8 + 0.1 × 22 = 4ns
性能提升比 = 20ns ÷ 4ns = 5
```

**答案**：性能提升比为5倍。

#### 3.5.2 多级缓存

**两级缓存系统**：

平均访问时间：
$$AAT = H_1 \times T_1 + (1-H_1) \times H_2 \times (T_1 + T_2) + (1-H_1)(1-H_2) \times (T_1 + T_2 + T_m)$$

其中：
- $H_1, H_2$：一级、二级缓存命中率
- $T_1, T_2, T_m$：一级缓存、二级缓存、主存访问时间

---

## 4. 主存储器系统

### 4.1 主存组织结构

#### 4.1.1 存储芯片组织

> **定义4.1（存储矩阵）**
> 
> 存储芯片内部采用矩阵方式组织存储单元，通过行地址和列地址访问特定存储位置。

**地址线分时复用**：
- RAS(Row Address Strobe)：行地址选通信号
- CAS(Column Address Strobe)：列地址选通信号
- 减少地址引脚数量，降低封装成本

#### 4.1.2 存储体组织

**单体存储器**：
- 结构简单，成本低
- 存在存储器冲突，影响性能

**多体存储器**：

> **定义4.2（多体存储器）**
> 
> 多体存储器由多个存储体组成，可以并行访问，提高存储器带宽。

**高位交叉存储器**：
- 地址的高位部分选择存储体
- 顺序访问时访问同一存储体
- 适用于单个大程序

**低位交叉存储器**：
- 地址的低位部分选择存储体
- 顺序访问时访问不同存储体
- 适用于连续地址访问，提高带宽

> **例题4.1**：某8体低位交叉存储器，存储体访问时间100ns，存储体周期150ns。求连续访问8个字的时间。

**解析**：
```
低位交叉存储，连续8个字分布在8个不同存储体
第1个字：0ns开始，100ns完成
第2个字：存储体周期/体数 = 150ns/8 ≈ 18.75ns开始
...
第8个字：7 × 18.75 = 131.25ns开始，231.25ns完成

由于第8个字在231.25ns完成，但存储体周期是150ns
实际完成时间 = max(231.25, 150) = 231.25ns
```

**答案**：连续访问8个字需要231.25ns。

### 4.2 主存技术

#### 4.2.1 DRAM技术

**DRAM特点**：
- 需要定期刷新以保持数据
- 集成度高，成本低
- 访问速度相对较慢

**DRAM刷新方式**：
1. **集中刷新**：在一个刷新周期内集中刷新所有行
2. **分散刷新**：每个存取周期刷新一行
3. **异步刷新**：将刷新周期分散到整个刷新时间内

**刷新开销计算**：
$$刷新开销比例 = \frac{刷新时间}{刷新周期} \times 100\%$$

#### 4.2.2 SRAM技术

**SRAM特点**：
- 不需要刷新，访问速度快
- 集成度低，成本高
- 功耗较大

**应用场景**：主要用于Cache存储器

#### 4.2.3 DDR技术演进

| DDR类型 | 数据速率 | 预取位宽 | 电压 |
|---------|----------|----------|------|
| DDR     | 2倍时钟  | 2位      | 2.5V |
| DDR2    | 4倍时钟  | 4位      | 1.8V |
| DDR3    | 8倍时钟  | 8位      | 1.5V |
| DDR4    | 8倍时钟  | 8位      | 1.2V |
| DDR5    | 8倍时钟  | 16位     | 1.1V |

### 4.3 错误检测与纠正

#### 4.3.1 奇偶校验

> **定义4.3（奇偶校验）**
> 
> 在数据位基础上增加一个校验位，使得包括校验位在内的所有位中1的个数为奇数(奇校验)或偶数(偶校验)。

**检错能力**：只能检测奇数个位的错误，不能纠错

#### 4.3.2 海明码

> **定义4.4（海明码）**
> 
> 海明码是一种线性纠错码，能够检测2位错误并纠正1位错误。

**校验位数量**：对于 $k$ 位信息位，需要 $r$ 位校验位，满足：
$$2^r \geq k + r + 1$$

**海明码编码步骤**：
1. 确定校验位数量和位置(2的幂次位置)
2. 计算各校验位的值
3. 形成完整的海明码

> **例题4.2**：用海明码编码4位数据1011，求7位海明码。

**解析**：
```
4位数据需要3位校验位：2³ = 8 > 4+3+1 = 8

位置安排：P₁P₂D₁P₃D₂D₃D₄
数据1011对应：__1_011

计算校验位：
P₁ = D₁ ⊕ D₂ ⊕ D₄ = 1 ⊕ 0 ⊕ 1 = 0
P₂ = D₁ ⊕ D₃ ⊕ D₄ = 1 ⊕ 1 ⊕ 1 = 1  
P₃ = D₂ ⊕ D₃ ⊕ D₄ = 0 ⊕ 1 ⊕ 1 = 0

海明码：0110011
```

**答案**：7位海明码为0110011。

---

## 5. 虚拟存储器

### 5.1 虚拟存储基本概念

> **定义5.1（虚拟存储器）**
> 
> 虚拟存储器是一种存储管理技术，为用户提供比物理内存更大的地址空间，通过软硬件结合实现程序的自动装入和替换。

#### 5.1.1 基本原理

**虚拟地址空间**：程序使用的逻辑地址空间
**物理地址空间**：实际内存的地址空间
**地址转换**：将虚拟地址转换为物理地址的过程

#### 5.1.2 实现条件

1. **一定容量的内存和外存**
2. **页表或段表等地址转换机构**
3. **中断机构**：处理缺页等异常
4. **地址转换机构**：硬件支持地址转换

### 5.2 分页存储管理

#### 5.2.1 基本概念

> **定义5.2（页面和页框）**
> 
> 页面是虚拟地址空间的固定大小单位，页框是物理内存的固定大小单位，两者大小相等。

**虚拟地址结构**：
```
┌─────────────┬─────────────────┐
│   页号(VPN)   │   页内偏移(Offset) │
└─────────────┴─────────────────┘
```

**物理地址结构**：
```
┌─────────────┬─────────────────┐
│  页框号(PFN)  │   页内偏移(Offset) │
└─────────────┴─────────────────┘
```

#### 5.2.2 页表结构

> **定义5.3（页表）**
> 
> 页表是记录虚拟页面与物理页框映射关系的数据结构。

**页表项(PTE)内容**：
- 有效位(Valid Bit)：页面是否在内存中
- 页框号(PFN)：物理页框地址
- 保护位：读、写、执行权限
- 修改位(Dirty Bit)：页面是否被修改
- 访问位(Reference Bit)：页面是否被访问

#### 5.2.3 多级页表

**两级页表结构**：
```
虚拟地址：│一级页号│二级页号│页内偏移│
         │   10   │   10   │   12   │(32位系统示例)
```

**地址转换过程**：
1. 用一级页号索引一级页表，得到二级页表基址
2. 用二级页号索引二级页表，得到页框号
3. 页框号与页内偏移组合得到物理地址

**优势**：
- 减少页表占用的内存空间
- 提高页表的局部性
- 支持稀疏地址空间

#### 5.2.4 快表(TLB)

> **定义5.4（快表TLB）**
> 
> 快表是一个小容量、高速的相联存储器，用于缓存最近使用的页表项。

**TLB工作过程**：
1. 检查TLB是否命中
2. 命中：直接获得物理地址
3. 不命中：访问页表，更新TLB

**TLB性能分析**：
$$EAT = \alpha \times (T_{TLB} + T_{memory}) + (1-\alpha) \times (T_{TLB} + T_{page\_table} + T_{memory})$$

其中：
- $\alpha$：TLB命中率
- $T_{TLB}$：TLB访问时间
- $T_{memory}$：内存访问时间  
- $T_{page\_table}$：页表访问时间

### 5.3 页面置换算法

#### 5.3.1 最优置换算法(OPT)

> **定义5.5（最优置换算法）**
> 
> 最优置换算法选择在未来最长时间不被访问的页面进行置换。

**特点**：
- 理论最优，实际无法实现
- 主要用于算法性能比较的基准

#### 5.3.2 先进先出(FIFO)

**算法特点**：
- 实现简单，开销小
- 可能产生Belady异常：分配页框增加，缺页率反而增加
- 不符合局部性原理

> **例题5.1**：页面访问序列为7,0,1,2,0,3,0,4,2,3,0,3,2,1,2,0,1,7,0,1，分配3个页框，使用FIFO算法计算缺页率。

**解析**：
```
访问序列：7,0,1,2,0,3,0,4,2,3,0,3,2,1,2,0,1,7,0,1
页框状态变化：

页框1 页框2 页框3   缺页?
7      -      -     是
7      0      -     是  
7      0      1     是
2      0      1     是
2      0      1     否
2      3      1     是
2      3      0     是
4      3      0     是
4      2      0     是
4      2      3     是
0      2      3     是
0      2      3     否
0      2      3     否
1      2      3     是
1      2      3     否
1      0      3     是
1      0      3     否
7      0      3     是
7      0      3     否
7      0      1     是

缺页次数：15次
总访问次数：20次
缺页率 = 15/20 = 75%
```

**答案**：缺页率为75%。

#### 5.3.3 最近最少使用(LRU)

**算法原理**：基于局部性原理，置换最近最少使用的页面

**实现方法**：
1. **堆栈实现**：维护页面访问的堆栈
2. **计数器实现**：为每个页面维护访问时间戳
3. **矩阵实现**：使用 $n \times n$ 矩阵记录访问顺序

#### 5.3.4 时钟置换算法

> **定义5.6（时钟置换算法）**
> 
> 时钟置换算法是LRU的近似实现，使用访问位和循环扫描指针。

**算法步骤**：
1. 检查当前指针指向页面的访问位
2. 访问位为0：选择该页面置换
3. 访问位为1：清除访问位，指针移动到下一页面
4. 重复步骤1-3直到找到置换页面

**改进版本**：
- **改进型时钟算法**：同时考虑访问位和修改位
- **WSClock算法**：结合工作集算法的优点

### 5.4 分段存储管理

#### 5.4.1 段的概念

> **定义5.7（段）**
> 
> 段是按照程序的逻辑结构划分的可变长度的存储单位。

**段的特点**：
- 长度可变，由程序逻辑决定
- 段内地址连续，段间地址可以不连续
- 便于程序的模块化管理

#### 5.4.2 段表结构

**段表项内容**：
- 段基址：段在内存中的起始地址
- 段长度：段的长度限制
- 存取权限：读、写、执行权限

**地址转换**：
```
虚拟地址：│段号│段内偏移│
物理地址 = 段基址 + 段内偏移
```

**地址有效性检查**：
$$段内偏移 < 段长度$$

#### 5.4.3 段页式管理

**特点**：
- 结合段式和页式的优点
- 程序按段划分，段内按页划分
- 既便于共享，又便于内存管理

**地址结构**：
```
虚拟地址：│段号│页号│页内偏移│
```

**地址转换过程**：
1. 用段号查段表，得到页表基址
2. 用页号查页表，得到页框号
3. 页框号与页内偏移组合得到物理地址

---

## 6. 存储器性能分析

### 6.1 性能建模

#### 6.1.1 访问时间建模

**Cache系统平均访问时间**：
$$T_{avg} = H_c \times T_c + (1-H_c) \times (T_c + T_m + T_{miss\_overhead})$$

**虚拟存储系统平均访问时间**：
$$T_{avg} = H_p \times T_{TLB+mem} + (1-H_p) \times T_{page\_fault}$$

其中：
- $H_p$：页面命中率
- $T_{TLB+mem}$：TLB和内存访问时间
- $T_{page\_fault}$：缺页处理时间

#### 6.1.2 带宽分析

**理论带宽**：
$$BW_{theoretical} = \frac{数据位宽 \times 时钟频率}{8}$$

**有效带宽**：
$$BW_{effective} = BW_{theoretical} \times 效率因子$$

效率因子取决于：
- 缓存命中率
- 存储器利用率
- 总线争用情况

### 6.2 性能优化策略

#### 6.2.1 Cache优化

**降低缺失率**：
- 增大Cache容量
- 提高相联度
- 优化替换算法
- 程序局部性优化

**降低缺失代价**：
- 使用写缓冲器
- 关键字优先
- 非阻塞Cache
- 多级Cache

**减少命中时间**：
- 简化Cache设计
- 虚拟Cache
- 流水线访问
- 路预测

#### 6.2.2 主存优化

**提高带宽**：
- 多体交叉存储
- 增加存储器位宽
- 使用高速存储器

**降低延迟**：
- 减少地址译码时间
- 优化存储器时序
- 使用同步存储器

### 6.3 现代存储技术

#### 6.3.1 新型存储器

**相变存储器(PCM)**：
- 非易失性，速度快
- 写次数有限
- 适用于存储级内存

**阻变存储器(RRAM)**：
- 功耗低，集成度高
- 可实现神经形态计算
- 在人工智能领域应用广泛

**磁性存储器(MRAM)**：
- 非易失性，速度快
- 无限写次数
- 抗辐射能力强

#### 6.3.2 存储器架构演进

**近数据计算(NDC)**：
- 在存储器附近进行计算
- 减少数据移动开销
- 提高能效比

**内存计算(PIM)**：
- 在存储器内部进行计算
- 突破存储墙限制
- 适用于大数据处理

---

## 7. 典型例题

### 7.1 缓存设计综合题

> **例题7.1**：设计一个64KB的Cache，主存容量4GB，块大小64B。要求：
> 1. 采用4路组相联映射
> 2. 使用LRU替换算法
> 3. 采用写回策略
> 4. 计算各地址字段长度
> 5. 分析硬件开销

**解析**：

**(1) 地址字段计算**：
```
Cache容量 = 64KB = 65536B
块大小 = 64B
总块数 = 65536 ÷ 64 = 1024块
4路组相联，组数 = 1024 ÷ 4 = 256组

主存容量 = 4GB = 2³²B
主存地址长度 = 32位

块内偏移位数 = log₂(64) = 6位
组索引位数 = log₂(256) = 8位  
标记位数 = 32 - 6 - 8 = 18位
```

**(2) Cache结构设计**：
每个Cache行包含：
- 有效位：1位
- 脏位：1位 (写回策略需要)
- 标记：18位
- 数据：64B = 512位
- LRU位：2位 (4路需要2位表示优先级)

**(3) 硬件开销分析**：
```
每行控制位数 = 1 + 1 + 18 + 2 = 22位
总控制位数 = 22 × 1024 = 22528位 = 2.75KB
数据位数 = 64KB
总存储开销 = 64KB + 2.75KB = 66.75KB
开销比例 = 2.75KB ÷ 64KB × 100% = 4.3%
```

**答案**：
- 地址字段：标记18位，组索引8位，块内偏移6位
- 硬件开销：控制信息2.75KB，开销比例4.3%

### 7.2 虚拟存储综合题

> **例题7.2**：某32位系统采用两级页表，页大小4KB，页表项大小4B。
> 1. 设计虚拟地址格式
> 2. 计算页表占用空间
> 3. 分析TLB对性能的影响

**解析**：

**(1) 虚拟地址格式设计**：
```
页大小 = 4KB = 2¹²B
页内偏移 = 12位

剩余地址位 = 32 - 12 = 20位
采用两级页表，平均分配：
一级页号 = 10位，二级页号 = 10位

虚拟地址格式：
┌──────────┬──────────┬──────────────┐
│一级页号 10位│二级页号 10位│页内偏移 12位│  
└──────────┴──────────┴──────────────┘
```

**(2) 页表空间计算**：
```
一级页表：
页表项数 = 2¹⁰ = 1024个
空间 = 1024 × 4B = 4KB (固定)

二级页表：
每个二级页表项数 = 2¹⁰ = 1024个  
每个二级页表空间 = 1024 × 4B = 4KB
最大二级页表数 = 1024个
最大二级页表空间 = 1024 × 4KB = 4MB

总页表空间：4KB (一级) + 最多4MB (二级) = 4MB + 4KB
```

**(3) TLB性能影响分析**：
假设TLB命中率90%，TLB访问时间1ns，内存访问时间100ns：

```
无TLB时访问时间：
EAT = 100ns (页表访问) + 100ns (数据访问) = 200ns

有TLB时访问时间：  
EAT = 0.9 × (1 + 100) + 0.1 × (1 + 100 + 100)
    = 0.9 × 101 + 0.1 × 201
    = 90.9 + 20.1 = 111ns

性能提升 = 200ns ÷ 111ns ≈ 1.8倍
```

**答案**：
- 地址格式：一级页号10位，二级页号10位，页内偏移12位
- 页表空间：最大4MB + 4KB
- TLB带来1.8倍性能提升

### 7.3 存储器性能优化题

> **例题7.3**：某系统存储器层次结构参数如下：
> - L1 Cache：32KB，2路组相联，命中时间1ns，命中率95%
> - L2 Cache：256KB，4路组相联，命中时间10ns，命中率85%  
> - 主存：访问时间100ns
> 
> 分析该系统的存储器性能，并提出优化建议。

**解析**：

**(1) 性能分析**：
```
L1 Cache未命中率 = 1 - 0.95 = 0.05
L2 Cache相对于L1的命中率 = 0.85
L2 Cache全局命中率 = 0.05 × 0.85 = 0.0425
主存访问概率 = 0.05 × (1 - 0.85) = 0.0075

平均访问时间：
EAT = 0.95 × 1 + 0.0425 × (1 + 10) + 0.0075 × (1 + 10 + 100)
    = 0.95 + 0.4675 + 0.8325
    = 2.25ns

每次访问的平均开销：
L1贡献：0.95 × 1 = 0.95ns (42.2%)
L2贡献：0.0425 × 11 = 0.47ns (20.9%)  
主存贡献：0.0075 × 111 = 0.83ns (36.9%)
```

**(2) 性能瓶颈识别**：
- 主存访问虽然概率低(0.75%)，但贡献了36.9%的时间开销
- L2 Cache命中率相对较低，有优化空间

**(3) 优化建议**：

**提高L2命中率**：
- 增大L2 Cache容量至512KB或1MB
- 提高L2相联度至8路或16路
- 优化程序局部性

**减少主存访问代价**：
- 使用预取技术
- 增加L2与主存间的带宽
- 考虑添加L3 Cache

**量化分析**：
假设L2命中率提升至90%：
```
新的EAT = 0.95 × 1 + 0.045 × 11 + 0.005 × 111
         = 0.95 + 0.495 + 0.555 = 2.0ns
性能提升 = 2.25ns ÷ 2.0ns = 12.5%
```

**答案**：
- 当前平均访问时间：2.25ns
- 主要瓶颈：主存访问代价过高
- 优化建议：提高L2命中率至90%，可获得12.5%性能提升

 