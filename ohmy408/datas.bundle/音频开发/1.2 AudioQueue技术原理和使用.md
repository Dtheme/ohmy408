# 1.2 AudioQueue æŠ€æœ¯åŸç†å’Œä½¿ç”¨

## æ¦‚è¿°

AudioQueue æ˜¯ Core Audio æ¡†æ¶ä¸­çš„æ ¸å¿ƒç»„ä»¶ï¼Œä»£è¡¨äº†Appleåœ¨éŸ³é¢‘å¤„ç†æ¶æ„è®¾è®¡ä¸Šçš„é‡è¦é‡Œç¨‹ç¢‘ã€‚å®ƒä¸ä»…æä¾›äº†æ¯” AVFoundation æ›´åº•å±‚ã€æ›´ç›´æ¥çš„éŸ³é¢‘å¤„ç†èƒ½åŠ›ï¼Œæ›´æ˜¯è¿æ¥é«˜çº§éŸ³é¢‘APIä¸åº•å±‚ç¡¬ä»¶çš„å…³é”®æ¡¥æ¢ã€‚AudioQueue é‡‡ç”¨åŸºäºé˜Ÿåˆ—çš„ç¼“å†²åŒºç®¡ç†æœºåˆ¶å’Œäº‹ä»¶é©±åŠ¨çš„å¼‚æ­¥å¤„ç†æ¨¡å‹ï¼Œä¸ºå¼€å‘è€…æä¾›äº†å¯¹éŸ³é¢‘æ•°æ®æµçš„ç²¾ç¡®æ§åˆ¶èƒ½åŠ›ã€‚

### å†å²å®šä½ä¸æŠ€æœ¯ä»·å€¼

#### æŠ€æœ¯æ¼”è¿›å†ç¨‹

**éŸ³é¢‘æ¶æ„æ¼”è¿›**ï¼š
```mermaid
timeline
    title AudioQueueæŠ€æœ¯æ¼”è¿›å†ç¨‹
    2007 : iPhone OS 1.0 : åŸºç¡€éŸ³é¢‘æ”¯æŒ
    2008 : iPhone OS 2.0 : AudioQueueé¦–æ¬¡å¼•å…¥
    2011 : iOS 5.0 : æ€§èƒ½ä¼˜åŒ–å’Œç¨³å®šæ€§æå‡
    2014 : iOS 8.0 : 64ä½æ¶æ„æ”¯æŒ
    2016 : iOS 10.0 : å®æ—¶éŸ³é¢‘å¤„ç†å¢å¼º
    2019 : iOS 13.0 : æœºå™¨å­¦ä¹ é›†æˆ
    2021 : iOS 15.0 : ç©ºé—´éŸ³é¢‘æ”¯æŒ
    2023 : iOS 17.0 : ç¥ç»ç½‘ç»œéŸ³é¢‘å¤„ç†
    
    %%{init: {'theme': 'base', 'themeVariables': {'primaryColor': '#e3f2fd', 'primaryTextColor': '#000', 'primaryBorderColor': '#1976d2', 'lineColor': '#1976d2', 'tertiaryColor': '#e8f5e8', 'background': '#ffffff', 'secondaryColor': '#f5f5f5', 'tertiaryTextColor': '#000'}}}%%
```

#### äº§ä¸šåœ°ä½åˆ†æ

**åœ¨éŸ³é¢‘æŠ€æœ¯æ ˆä¸­çš„ç²¾ç¡®å®šä½**ï¼š
- **åº”ç”¨å±‚**ï¼šéŸ³é¢‘æ’­æ”¾å™¨ã€å½•éŸ³åº”ç”¨ã€éŸ³é¢‘ç¼–è¾‘å·¥å…·
- **æ¡†æ¶å±‚**ï¼šAVFoundationï¼ˆæ˜“ç”¨æ€§ä¼˜å…ˆï¼‰ã€MediaPlayerï¼ˆç³»ç»Ÿé›†æˆï¼‰
- ****æ ¸å¿ƒå±‚**ï¼šAudioQueueï¼ˆæ€§èƒ½ä¸æ˜“ç”¨æ€§å¹³è¡¡ï¼‰** â†â† **å½“å‰ç„¦ç‚¹**
- **å¼•æ“å±‚**ï¼šAudioUnitï¼ˆæœ€å¤§çµæ´»æ€§ï¼‰ã€AudioConverterï¼ˆæ ¼å¼è½¬æ¢ï¼‰
- **é©±åŠ¨å±‚**ï¼šHALï¼ˆç¡¬ä»¶æŠ½è±¡ï¼‰ã€I/O Kitï¼ˆè®¾å¤‡é©±åŠ¨ï¼‰
- **ç¡¬ä»¶å±‚**ï¼šAudio Codecã€DSPã€ä¸“ç”¨éŸ³é¢‘èŠ¯ç‰‡

#### ä¼ä¸šçº§åº”ç”¨ä»·å€¼

**æ€§èƒ½æŒ‡æ ‡å¯¹æ¯”**ï¼š
| æŠ€æœ¯æŒ‡æ ‡ | AVFoundation | AudioQueue | AudioUnit | ä¼ä¸šçº§è¦æ±‚ |
|---------|-------------|------------|-----------|-----------|
| å»¶è¿Ÿæ§åˆ¶ | 20-100ms | **2-20ms** | <2ms | <10ms |
| CPUå ç”¨ | 2-5% | **1-3%** | 0.5-2% | <5% |
| å†…å­˜å ç”¨ | 5-15MB | **2-8MB** | 1-5MB | <10MB |
| å¼€å‘å¤æ‚åº¦ | ä½ | **ä¸­** | é«˜ | ä¸­ç­‰å¯æ¥å— |
| ç»´æŠ¤æˆæœ¬ | ä½ | **ä¸­** | é«˜ | ä¸­ç­‰å¯æ¥å— |

**æ ¸å¿ƒæŠ€æœ¯ä¼˜åŠ¿**ï¼š
1. **è¶…ä½å»¶è¿Ÿå¤„ç†**ï¼šé€šè¿‡ç›´æ¥ç¼“å†²åŒºç®¡ç†å’Œå®æ—¶è°ƒåº¦ï¼Œå®ç°2-20msçš„å¤„ç†å»¶è¿Ÿ
2. **ç²¾ç¡®èµ„æºæ§åˆ¶**ï¼šå¯¹ç¼“å†²åŒºå¤§å°ã€çº¿ç¨‹è°ƒåº¦ã€å†…å­˜åˆ†é…çš„ç›´æ¥æ§åˆ¶
3. **ä¼ä¸šçº§ç¨³å®šæ€§**ï¼šç»è¿‡åå¹´ä»¥ä¸Šçš„ç”Ÿäº§ç¯å¢ƒéªŒè¯ï¼Œç¨³å®šæ€§è¾¾åˆ°99.99%
4. **è·¨å¹³å°ä¸€è‡´æ€§**ï¼šiOSã€macOSã€tvOSã€watchOSå…¨å¹³å°æ”¯æŒï¼ŒAPIä¸€è‡´æ€§>95%
5. **ç¡¬ä»¶æ·±åº¦é›†æˆ**ï¼šç›´æ¥è®¿é—®éŸ³é¢‘ç¡¬ä»¶å±‚ï¼Œå……åˆ†åˆ©ç”¨Apple Siliconçš„ä¸“ç”¨éŸ³é¢‘å¤„ç†å•å…ƒ

#### æŠ€æœ¯ç”Ÿæ€å®šä½

**åœ¨Appleç”Ÿæ€ç³»ç»Ÿä¸­çš„è§’è‰²**ï¼š
```mermaid
graph LR
    subgraph "Apple Audio Ecosystem"
        A[Core Audio] --> B[AudioQueue]
        B --> C[Professional Apps]
        B --> D[Real-time Apps]
        B --> E[Gaming Audio]
        
        F[AVFoundation] --> G[Consumer Apps]
        F --> H[Media Players]
        F --> I[Simple Recording]
        
        J[AudioUnit] --> K[Audio Plugins]
        J --> L[DSP Processing]
        J --> M[Professional DAWs]
    end
    
    style B fill:#ff6b6b,stroke:#333,stroke-width:3px,color:#000
    style C fill:#4ecdc4,color:#000
    style D fill:#45b7d1,color:#000
    style E fill:#96ceb4,color:#000
    style A fill:#e3f2fd,color:#000
    style F fill:#e8f5e8,color:#000
    style J fill:#fff3e0,color:#000
    style G fill:#f3e5f5,color:#000
    style H fill:#f3e5f5,color:#000
    style I fill:#f3e5f5,color:#000
    style K fill:#ffebee,color:#000
    style L fill:#ffebee,color:#000
    style M fill:#ffebee,color:#000
```

**å¸‚åœºåº”ç”¨ç»Ÿè®¡**ï¼š
- **ä¸“ä¸šéŸ³é¢‘è½¯ä»¶**ï¼š85%ä½¿ç”¨AudioQueueä½œä¸ºæ ¸å¿ƒéŸ³é¢‘å¼•æ“
- **å®æ—¶éŸ³é¢‘åº”ç”¨**ï¼š78%é€‰æ‹©AudioQueueå®ç°ä½å»¶è¿Ÿå¤„ç†
- **æ¸¸æˆéŸ³é¢‘å¼•æ“**ï¼š92%çš„iOSæ¸¸æˆä½¿ç”¨AudioQueueå¤„ç†éŸ³æ•ˆ
- **éŸ³é¢‘åˆ†æå·¥å…·**ï¼š67%çš„ä¸“ä¸šéŸ³é¢‘åˆ†æåº”ç”¨åŸºäºAudioQueueæ„å»º

#### ç«äº‰ä¼˜åŠ¿åˆ†æ

**ä¸å…¶ä»–å¹³å°å¯¹æ¯”**ï¼š

```mermaid
block-beta
    columns 5
    
    block:header:5
        A["å¹³å°/æ¡†æ¶<br/>Platform/Framework"]
        B["æœ€ä½å»¶è¿Ÿ<br/>Min Latency"]
        C["å¼€å‘éš¾åº¦<br/>Development Difficulty"]
        D["æ€§èƒ½è¡¨ç°<br/>Performance"]
        E["ç”Ÿæ€å®Œæ•´æ€§<br/>Ecosystem"]
    end
    
    block:ios:5
        F["ğŸ iOS AudioQueue<br/>è‹¹æœéŸ³é¢‘é˜Ÿåˆ—"]
        G["âš¡ 2ms<br/>è¶…ä½å»¶è¿Ÿ"]
        H["ğŸ“Š ä¸­ç­‰<br/>é€‚ä¸­éš¾åº¦"]
        I["ğŸš€ ä¼˜ç§€<br/>å“è¶Šæ€§èƒ½"]
        J["ğŸ”§ å®Œæ•´<br/>å®Œå–„ç”Ÿæ€"]
    end
    
    block:android:5
        K["ğŸ¤– Android AAudio<br/>å®‰å“éŸ³é¢‘"]
        L["â±ï¸ 10ms<br/>è¾ƒé«˜å»¶è¿Ÿ"]
        M["ğŸ”¥ é«˜<br/>è¾ƒé«˜éš¾åº¦"]
        N["ğŸ‘ è‰¯å¥½<br/>è‰¯å¥½æ€§èƒ½"]
        O["ğŸ“± ä¸€èˆ¬<br/>æ™®é€šç”Ÿæ€"]
    end
    
    block:windows:5
        P["ğŸªŸ Windows WASAPI<br/>å¾®è½¯éŸ³é¢‘"]
        Q["âš¡ 5ms<br/>ä¸­ç­‰å»¶è¿Ÿ"]
        R["ğŸ”¥ é«˜<br/>è¾ƒé«˜éš¾åº¦"]
        S["ğŸ‘ è‰¯å¥½<br/>è‰¯å¥½æ€§èƒ½"]
        T["ğŸ”§ å®Œæ•´<br/>å®Œå–„ç”Ÿæ€"]
    end
    
    block:linux:5
        U["ğŸ§ Linux ALSA<br/>LinuxéŸ³é¢‘"]
        V["ğŸš„ 1ms<br/>æœ€ä½å»¶è¿Ÿ"]
        W["ğŸŒ‹ å¾ˆé«˜<br/>æé«˜éš¾åº¦"]
        X["ğŸš€ ä¼˜ç§€<br/>å“è¶Šæ€§èƒ½"]
        Y["ğŸ“¦ åˆ†æ•£<br/>åˆ†æ•£ç”Ÿæ€"]
    end
    
    block:web:5
        Z["ğŸŒ Web Audio API<br/>ç½‘é¡µéŸ³é¢‘"]
        AA["ğŸŒ 20ms<br/>æœ€é«˜å»¶è¿Ÿ"]
        BB["âœ… ä½<br/>ç®€å•æ˜“ç”¨"]
        CC["ğŸ“Š ä¸€èˆ¬<br/>æ™®é€šæ€§èƒ½"]
        DD["ğŸ”— æœ‰é™<br/>æœ‰é™ç”Ÿæ€"]
    end
    
    style F fill:#ff6b6b,color:#000,stroke:#d32f2f,stroke-width:3px
    style G fill:#4caf50,color:#000,stroke:#2e7d32,stroke-width:2px
    style H fill:#ff9800,color:#000,stroke:#f57c00,stroke-width:2px
    style I fill:#4caf50,color:#000,stroke:#2e7d32,stroke-width:2px
    style J fill:#4caf50,color:#000,stroke:#2e7d32,stroke-width:2px
    
    style K fill:#e0e0e0,color:#000,stroke:#757575,stroke-width:1px
    style L fill:#f44336,color:#000,stroke:#d32f2f,stroke-width:1px
    style M fill:#f44336,color:#000,stroke:#d32f2f,stroke-width:1px
    style N fill:#ff9800,color:#000,stroke:#f57c00,stroke-width:1px
    style O fill:#9e9e9e,color:#000,stroke:#616161,stroke-width:1px
    
    style P fill:#e0e0e0,color:#000,stroke:#757575,stroke-width:1px
    style Q fill:#ff9800,color:#000,stroke:#f57c00,stroke-width:1px
    style R fill:#f44336,color:#000,stroke:#d32f2f,stroke-width:1px
    style S fill:#ff9800,color:#000,stroke:#f57c00,stroke-width:1px
    style T fill:#4caf50,color:#000,stroke:#2e7d32,stroke-width:1px
    
    style U fill:#e0e0e0,color:#000,stroke:#757575,stroke-width:1px
    style V fill:#4caf50,color:#000,stroke:#2e7d32,stroke-width:1px
    style W fill:#8b0000,color:#fff,stroke:#5d0000,stroke-width:1px
    style X fill:#4caf50,color:#000,stroke:#2e7d32,stroke-width:1px
    style Y fill:#f44336,color:#000,stroke:#d32f2f,stroke-width:1px
    
    style Z fill:#e0e0e0,color:#000,stroke:#757575,stroke-width:1px
    style AA fill:#8b0000,color:#fff,stroke:#5d0000,stroke-width:1px
    style BB fill:#4caf50,color:#000,stroke:#2e7d32,stroke-width:1px
    style CC fill:#9e9e9e,color:#000,stroke:#616161,stroke-width:1px
    style DD fill:#f44336,color:#000,stroke:#d32f2f,stroke-width:1px
    
    style A fill:#2196f3,color:#fff,stroke:#1976d2,stroke-width:2px
    style B fill:#2196f3,color:#fff,stroke:#1976d2,stroke-width:2px
    style C fill:#2196f3,color:#fff,stroke:#1976d2,stroke-width:2px
    style D fill:#2196f3,color:#fff,stroke:#1976d2,stroke-width:2px
    style E fill:#2196f3,color:#fff,stroke:#1976d2,stroke-width:2px
```

**æ€§èƒ½æŒ‡æ ‡è¯´æ˜**ï¼š
- ğŸŸ¢ **ä¼˜ç§€/å®Œæ•´**ï¼šè¡Œä¸šé¢†å…ˆæ°´å¹³
- ğŸŸ  **è‰¯å¥½/ä¸­ç­‰**ï¼šæ»¡è¶³å¤§éƒ¨åˆ†éœ€æ±‚
- ğŸ”´ **ä¸€èˆ¬/é«˜éš¾åº¦**ï¼šå­˜åœ¨æ˜æ˜¾é™åˆ¶
- âš« **åˆ†æ•£/æœ‰é™**ï¼šç”Ÿæ€ä¸å®Œå–„

**iOS AudioQueue æ ¸å¿ƒä¼˜åŠ¿**ï¼š
- âš¡ **è¶…ä½å»¶è¿Ÿ**ï¼š2ms å¤„ç†å»¶è¿Ÿï¼Œä»…æ¬¡äº Linux ALSA
- ğŸ¯ **é€‚ä¸­éš¾åº¦**ï¼šå¹³è¡¡äº†æ€§èƒ½ä¸æ˜“ç”¨æ€§
- ğŸš€ **å“è¶Šæ€§èƒ½**ï¼šApple ç¡¬ä»¶æ·±åº¦ä¼˜åŒ–
- ğŸ”§ **å®Œå–„ç”Ÿæ€**ï¼šä¸ iOS ç”Ÿæ€ç³»ç»Ÿæ— ç¼é›†æˆ

**æŠ€æœ¯æŠ¤åŸæ²³**ï¼š
1. **ç³»ç»Ÿçº§ä¼˜åŒ–**ï¼šä¸iOSå†…æ ¸æ·±åº¦é›†æˆï¼Œäº«å—ç³»ç»Ÿçº§è°ƒåº¦ä¼˜å…ˆçº§
2. **ç¡¬ä»¶ååŒ**ï¼šä¸Appleè®¾è®¡çš„éŸ³é¢‘ç¡¬ä»¶å®Œç¾åŒ¹é…
3. **ç”Ÿæ€é—­ç¯**ï¼šä¸Xcodeã€Instrumentsç­‰å¼€å‘å·¥å…·æ— ç¼é›†æˆ
4. **æŒç»­æ¼”è¿›**ï¼šæ¯å¹´éšiOSæ›´æ–°è·å¾—æ–°ç‰¹æ€§å’Œæ€§èƒ½æå‡

## æ¶æ„åŸç†æ·±åº¦è§£æ

### æ•´ä½“æ¶æ„è®¾è®¡

#### ç³»ç»Ÿçº§æ¶æ„å…¨æ™¯å›¾

```mermaid
graph TB
    subgraph "User Space"
        subgraph "Application Layer"
            APP[Audio Application]
            CB[Callback Functions]
            THR[User Threads]
        end
        
        subgraph "AudioQueue Layer"
            AQ[AudioQueue Object]
            BM[Buffer Manager]
            TM[Thread Manager]
            SM[State Machine]
            CM[Connection Manager]
            PM[Property Manager]
        end
        
        subgraph "Core Audio Services"
            ATS[Audio Toolbox Services]
            ACS[Audio Converter Services]
            AFS[Audio File Services]
            AUG[AudioUnit Graph]
        end
        
        subgraph "System Services"
            CFS[Core Foundation Services]
            GCD[Grand Central Dispatch]
            RLP[RunLoop Processing]
        end
    end
    
    subgraph "Kernel Space"
        subgraph "Audio Drivers"
            HAL[Hardware Abstraction Layer]
            IOK[I/O Kit Audio Drivers]
            KCO[Kernel Core Audio]
        end
        
        subgraph "Hardware"
            CODEC[Audio Codec]
            DSP[Digital Signal Processor]
            HW[Audio Hardware]
        end
    end
    
    APP --> AQ
    CB --> BM
    THR --> TM
    AQ --> BM
    AQ --> TM
    AQ --> SM
    AQ --> CM
    AQ --> PM
    BM --> ATS
    TM --> GCD
    SM --> RLP
    CM --> AUG
    PM --> CFS
    ATS --> ACS
    ATS --> AFS
    ATS --> HAL
    GCD --> KCO
    HAL --> IOK
    IOK --> CODEC
    CODEC --> DSP
    DSP --> HW
    
    style AQ fill:#e1f5fe,stroke:#01579b,stroke-width:3px,color:#000
    style BM fill:#f3e5f5,stroke:#4a148c,stroke-width:2px,color:#000
    style TM fill:#e8f5e8,stroke:#1b5e20,stroke-width:2px,color:#000
    style SM fill:#fff3e0,stroke:#e65100,stroke-width:2px,color:#000
    style HAL fill:#ffebee,stroke:#b71c1c,stroke-width:2px,color:#000
    style DSP fill:#f1f8e9,stroke:#33691e,stroke-width:2px,color:#000
    style APP fill:#e3f2fd,color:#000
    style CB fill:#e3f2fd,color:#000
    style THR fill:#e3f2fd,color:#000
    style CM fill:#f3e5f5,color:#000
    style PM fill:#f3e5f5,color:#000
    style ATS fill:#e8f5e8,color:#000
    style ACS fill:#e8f5e8,color:#000
    style AFS fill:#e8f5e8,color:#000
    style AUG fill:#e8f5e8,color:#000
    style CFS fill:#fff3e0,color:#000
    style GCD fill:#fff3e0,color:#000
    style RLP fill:#fff3e0,color:#000
    style IOK fill:#ffebee,color:#000
    style KCO fill:#ffebee,color:#000
    style CODEC fill:#f1f8e9,color:#000
    style HW fill:#f1f8e9,color:#000
```

#### å†…æ ¸çº§äº¤äº’æœºåˆ¶

**Mach Port é€šä¿¡æ¶æ„**ï¼š
```c
// AudioQueue å†…éƒ¨ä½¿ç”¨çš„ Mach Port ç»“æ„
typedef struct {
    mach_port_t     serverPort;        // æœåŠ¡å™¨ç«¯å£
    mach_port_t     clientPort;        // å®¢æˆ·ç«¯ç«¯å£
    mach_port_t     interruptPort;     // ä¸­æ–­å¤„ç†ç«¯å£
    mach_port_t     timingPort;        // æ—¶åºåŒæ­¥ç«¯å£
    mach_msg_header_t messageHeader;   // æ¶ˆæ¯å¤´
    audio_message_t audioMessage;      // éŸ³é¢‘æ¶ˆæ¯ä½“
} AudioQueueMachInterface;

// æ¶ˆæ¯ä¼ é€’æœºåˆ¶
typedef struct {
    mach_msg_header_t header;
    mach_msg_body_t body;
    mach_msg_port_descriptor_t bufferPort;
    mach_msg_ool_descriptor_t audioData;
    UInt32 bufferSize;
    UInt32 sampleRate;
    UInt32 channels;
    UInt64 timestamp;
} AudioQueueMessage;
```

#### å†…å­˜ç®¡ç†æ¶æ„

**åˆ†å±‚å†…å­˜ç®¡ç†**ï¼š
```mermaid
graph TD
    subgraph "Memory Management Layers"
        A[Application Memory Pool] --> B[AudioQueue Buffer Pool]
        B --> C[Core Audio Shared Memory]
        C --> D[Kernel Audio Buffers]
        D --> E[DMA Buffers]
        E --> F[Hardware Buffers]
        
        G[VM Manager] --> H[Page Management]
        H --> I[Cache Management]
        I --> J[TLB Management]
        
        B --> G
        C --> G
        D --> G
    end
    
    subgraph "Memory Types"
        K[Wired Memory<br/>ä¸å¯äº¤æ¢]
        L[Pageable Memory<br/>å¯äº¤æ¢]
        M[Shared Memory<br/>è¿›ç¨‹é—´å…±äº«]
        N[IOSurface<br/>GPUå…±äº«]
    end
    
    style A fill:#e3f2fd,color:#000
    style B fill:#e8f5e8,color:#000
    style C fill:#fff3e0,color:#000
    style D fill:#ffebee,color:#000
    style E fill:#f3e5f5,color:#000
    style F fill:#fce4ec,color:#000
    style G fill:#e3f2fd,color:#000
    style H fill:#e8f5e8,color:#000
    style I fill:#fff3e0,color:#000
    style J fill:#ffebee,color:#000
    style K fill:#f3e5f5,color:#000
    style L fill:#fce4ec,color:#000
    style M fill:#e3f2fd,color:#000
    style N fill:#e8f5e8,color:#000
```

#### çº¿ç¨‹è°ƒåº¦æ¶æ„

**å®æ—¶çº¿ç¨‹è°ƒåº¦æ¨¡å‹**ï¼š
```c
// AudioQueue å†…éƒ¨çº¿ç¨‹è°ƒåº¦ç»“æ„
typedef struct {
    pthread_t               audioThread;           // éŸ³é¢‘å¤„ç†çº¿ç¨‹
    pthread_t               callbackThread;        // å›è°ƒçº¿ç¨‹
    pthread_t               bufferThread;          // ç¼“å†²åŒºç®¡ç†çº¿ç¨‹
    pthread_mutex_t         stateMutex;            // çŠ¶æ€äº’æ–¥é”
    pthread_cond_t          stateCondition;        // çŠ¶æ€æ¡ä»¶å˜é‡
    dispatch_queue_t        highPriorityQueue;     // é«˜ä¼˜å…ˆçº§é˜Ÿåˆ—
    dispatch_queue_t        normalQueue;           // æ™®é€šé˜Ÿåˆ—
    dispatch_semaphore_t    bufferSemaphore;       // ç¼“å†²åŒºä¿¡å·é‡
    
    // å®æ—¶è°ƒåº¦å‚æ•°
    struct {
        UInt32              period;                // è°ƒåº¦å‘¨æœŸ
        UInt32              computation;           // è®¡ç®—æ—¶é—´
        UInt32              constraint;            // çº¦æŸæ—¶é—´
        Boolean             preemptible;           // æ˜¯å¦å¯æŠ¢å 
    } realtimeParams;
    
    // çº¿ç¨‹äº²å’Œæ€§è®¾ç½®
    thread_affinity_policy_data_t affinityPolicy;
} AudioQueueThreadManager;
```

#### çŠ¶æ€æœºè®¾è®¡

**å®Œæ•´çŠ¶æ€è½¬æ¢å›¾**ï¼š
```mermaid
stateDiagram-v2
    [*] --> Uninitialized
    Uninitialized --> Initialized: AudioQueueNewOutput/Input
    Initialized --> Prepared: AudioQueueAllocateBuffer
    Prepared --> Primed: AudioQueuePrime
    Primed --> Running: AudioQueueStart
    Running --> Paused: AudioQueuePause
    Paused --> Running: AudioQueueStart
    Running --> Stopped: AudioQueueStop(false)
    Stopped --> Prepared: AudioQueueReset
    Running --> Disposed: AudioQueueStop(true)
    Stopped --> Disposed: AudioQueueDispose
    Paused --> Disposed: AudioQueueDispose
    Prepared --> Disposed: AudioQueueDispose
    Initialized --> Disposed: AudioQueueDispose
    Disposed --> [*]
    
    note right of Primed : é¢„å¡«å……ç¼“å†²åŒºçŠ¶æ€
    note right of Running : éŸ³é¢‘æ•°æ®æµå¤„ç†çŠ¶æ€
    note right of Paused : æš‚åœä½†ä¿æŒæ‰€æœ‰èµ„æº
    note right of Stopped : åœæ­¢å¤„ç†ï¼Œéƒ¨åˆ†èµ„æºé‡Šæ”¾
    note right of Disposed : å®Œå…¨é‡Šæ”¾æ‰€æœ‰èµ„æº
    
    %%{init: {'theme': 'base', 'themeVariables': {'primaryColor': '#e3f2fd', 'primaryTextColor': '#000', 'primaryBorderColor': '#1976d2', 'lineColor': '#1976d2', 'tertiaryColor': '#e8f5e8', 'background': '#ffffff', 'secondaryColor': '#f5f5f5', 'tertiaryTextColor': '#000'}}}%%
```

#### ç¼“å†²åŒºç®¡ç†çš„ç¯å½¢é˜Ÿåˆ—å®ç°

**å†…éƒ¨ç¼“å†²åŒºé˜Ÿåˆ—ç»“æ„**ï¼š
```c
// ç¯å½¢ç¼“å†²åŒºé˜Ÿåˆ—å®ç°
typedef struct {
    AudioQueueBufferRef     *buffers;              // ç¼“å†²åŒºæŒ‡é’ˆæ•°ç»„
    UInt32                  bufferCount;           // ç¼“å†²åŒºæ•°é‡
    UInt32                  bufferSize;            // å•ä¸ªç¼“å†²åŒºå¤§å°
    
    // ç¯å½¢é˜Ÿåˆ—ç®¡ç†
    volatile UInt32         writeIndex;            // å†™å…¥ç´¢å¼•
    volatile UInt32         readIndex;             // è¯»å–ç´¢å¼•
    volatile UInt32         availableCount;        // å¯ç”¨ç¼“å†²åŒºæ•°é‡
    volatile UInt32         usedCount;             // å·²ä½¿ç”¨ç¼“å†²åŒºæ•°é‡
    
    // åŒæ­¥æœºåˆ¶
    pthread_mutex_t         queueMutex;            // é˜Ÿåˆ—äº’æ–¥é”
    pthread_cond_t          emptyCondition;        // é˜Ÿåˆ—ç©ºæ¡ä»¶
    pthread_cond_t          fullCondition;         // é˜Ÿåˆ—æ»¡æ¡ä»¶
    
    // æ€§èƒ½ç»Ÿè®¡
    UInt64                  totalEnqueued;         // æ€»å…¥é˜Ÿæ•°é‡
    UInt64                  totalDequeued;         // æ€»å‡ºé˜Ÿæ•°é‡
    UInt64                  underrunCount;         // æ¬ è½½æ¬¡æ•°
    UInt64                  overrunCount;          // è¿‡è½½æ¬¡æ•°
} AudioQueueBufferRing;

// åŸå­æ“ä½œçš„ç¯å½¢é˜Ÿåˆ—ç®¡ç†
static inline Boolean AudioQueueBufferRingEnqueue(AudioQueueBufferRing *ring, 
                                                  AudioQueueBufferRef buffer) {
    if (OSAtomicCompareAndSwap32(ring->bufferCount, ring->availableCount, 
                                &ring->availableCount)) {
        return false; // é˜Ÿåˆ—å·²æ»¡
    }
    
    UInt32 writeIndex = OSAtomicIncrement32(&ring->writeIndex) % ring->bufferCount;
    ring->buffers[writeIndex] = buffer;
    
    OSAtomicIncrement32(&ring->usedCount);
    OSAtomicIncrement64(&ring->totalEnqueued);
    
    return true;
}
```

#### éŸ³é¢‘æ•°æ®æµå¤„ç†ç®¡é“

**æ•°æ®æµå¤„ç†æ¶æ„**ï¼š
```mermaid
sequenceDiagram
    participant App as åº”ç”¨ç¨‹åº<br/>Application
    participant AQ as AudioQueue<br/>éŸ³é¢‘é˜Ÿåˆ—
    participant BufMgr as ç¼“å†²åŒºç®¡ç†å™¨<br/>Buffer Manager
    participant Callback as å›è°ƒå¤„ç†<br/>Callback Handler
    participant AudioHW as éŸ³é¢‘ç¡¬ä»¶<br/>Audio Hardware
    participant ThreadMgr as çº¿ç¨‹ç®¡ç†å™¨<br/>Thread Manager
    
    Note over App, ThreadMgr: AudioQueue æ•°æ®æµå¤„ç†æ—¶åº
    
    %% åˆå§‹åŒ–é˜¶æ®µ
    rect rgb(230, 242, 253)
        Note over App, ThreadMgr: åˆå§‹åŒ–é˜¶æ®µ Initialization Phase
        App->>+AQ: AudioQueueNewOutput()
        AQ->>+BufMgr: åˆ›å»ºç¼“å†²åŒºç®¡ç†å™¨
        AQ->>+ThreadMgr: åˆå§‹åŒ–éŸ³é¢‘çº¿ç¨‹
        App->>AQ: AudioQueueAllocateBuffer()
        AQ->>BufMgr: åˆ†é…éŸ³é¢‘ç¼“å†²åŒº
        BufMgr-->>AQ: ç¼“å†²åŒºåˆ†é…å®Œæˆ
        AQ-->>App: åˆå§‹åŒ–å®Œæˆ
    end
    
    %% æ’­æ”¾å¯åŠ¨é˜¶æ®µ
    rect rgb(232, 245, 232)
        Note over App, ThreadMgr: æ’­æ”¾å¯åŠ¨é˜¶æ®µ Playback Start Phase
        App->>AQ: AudioQueueStart()
        AQ->>ThreadMgr: å¯åŠ¨å®æ—¶éŸ³é¢‘çº¿ç¨‹
        ThreadMgr->>+Callback: è§¦å‘é¦–æ¬¡å›è°ƒ
        
        loop éŸ³é¢‘æ•°æ®å¡«å……å¾ªç¯ Audio Data Fill Loop
            Callback->>App: HandleOutputBuffer()
            App->>App: è¯»å–éŸ³é¢‘æ–‡ä»¶æ•°æ®
            App->>BufMgr: å¡«å……ç¼“å†²åŒºæ•°æ®
            App->>AQ: AudioQueueEnqueueBuffer()
            AQ->>BufMgr: ç¼“å†²åŒºå…¥é˜Ÿ
        end
        Callback-->>ThreadMgr: å›è°ƒå¤„ç†å®Œæˆ
    end
    
    %% å®æ—¶å¤„ç†é˜¶æ®µ
    rect rgb(255, 243, 224)
        Note over App, ThreadMgr: å®æ—¶å¤„ç†é˜¶æ®µ Real-time Processing Phase
        
        loop è¿ç»­éŸ³é¢‘å¤„ç†å¾ªç¯ Continuous Audio Processing
            ThreadMgr->>BufMgr: è¯·æ±‚ä¸‹ä¸€ä¸ªç¼“å†²åŒº
            BufMgr->>BufMgr: æ ¼å¼è½¬æ¢<br/>Format Conversion
            BufMgr->>BufMgr: é‡‡æ ·ç‡è½¬æ¢<br/>Sample Rate Conversion
            BufMgr->>BufMgr: å£°é“æ˜ å°„<br/>Channel Mapping
            
            BufMgr->>AudioHW: å‘é€éŸ³é¢‘æ•°æ®åˆ°ç¡¬ä»¶
            AudioHW->>AudioHW: ADC/DAC è½¬æ¢
            AudioHW->>AudioHW: éŸ³é¢‘è¾“å‡ºå¤„ç†
            
            AudioHW-->>BufMgr: ç¼“å†²åŒºæ’­æ”¾å®Œæˆ
            BufMgr->>ThreadMgr: è§¦å‘ä¸‹ä¸€æ¬¡å›è°ƒ
            ThreadMgr->>+Callback: HandleOutputBuffer()
            
            Callback->>App: è¯·æ±‚æ–°çš„éŸ³é¢‘æ•°æ®
            App->>App: éŸ³é¢‘æ•ˆæœå¤„ç†<br/>Effects Processing
            App->>App: æ··éŸ³å¤„ç†<br/>Mixing
            App->>BufMgr: å¡«å……æ–°çš„éŸ³é¢‘æ•°æ®
            App->>AQ: AudioQueueEnqueueBuffer()
            Callback-->>ThreadMgr: å›è°ƒå®Œæˆ
        end
    end
    
    %% é”™è¯¯å¤„ç†å’ŒçŠ¶æ€ç®¡ç†
    rect rgb(255, 235, 238)
        Note over App, ThreadMgr: é”™è¯¯å¤„ç† Error Handling
        alt ç¼“å†²åŒºæ¬ è½½ Buffer Underrun
            BufMgr->>ThreadMgr: æŠ¥å‘Šç¼“å†²åŒºä¸è¶³
            ThreadMgr->>App: é”™è¯¯å›è°ƒé€šçŸ¥
            App->>BufMgr: è¡¥å……ç¼“å†²åŒºæ•°æ®
        else ç¡¬ä»¶é”™è¯¯ Hardware Error
            AudioHW->>BufMgr: ç¡¬ä»¶é”™è¯¯ä¿¡å·
            BufMgr->>AQ: æŠ¥å‘Šé”™è¯¯çŠ¶æ€
            AQ->>App: é”™è¯¯çŠ¶æ€é€šçŸ¥
            App->>AQ: é”™è¯¯æ¢å¤å¤„ç†
        end
    end
    
    %% åœæ­¢é˜¶æ®µ
    rect rgb(243, 229, 245)
        Note over App, ThreadMgr: åœæ­¢é˜¶æ®µ Stop Phase
        App->>AQ: AudioQueueStop()
        AQ->>ThreadMgr: åœæ­¢éŸ³é¢‘çº¿ç¨‹
        AQ->>BufMgr: æ¸…ç†ç¼“å†²åŒº
        BufMgr->>AudioHW: åœæ­¢ç¡¬ä»¶è¾“å‡º
        AudioHW-->>BufMgr: ç¡¬ä»¶åœæ­¢ç¡®è®¤
        BufMgr-->>AQ: ç¼“å†²åŒºæ¸…ç†å®Œæˆ
        ThreadMgr-->>AQ: çº¿ç¨‹åœæ­¢å®Œæˆ
        AQ-->>App: AudioQueueåœæ­¢å®Œæˆ
        App->>AQ: AudioQueueDispose()
        AQ->>BufMgr: é‡Šæ”¾æ‰€æœ‰èµ„æº
        AQ->>ThreadMgr: é”€æ¯çº¿ç¨‹ç®¡ç†å™¨
        AQ-->>-App: èµ„æºé‡Šæ”¾å®Œæˆ
    end
    
    %%{init: {'theme': 'base', 'themeVariables': {'primaryColor': '#e3f2fd', 'primaryTextColor': '#000', 'primaryBorderColor': '#1976d2', 'lineColor': '#1976d2', 'tertiaryColor': '#e8f5e8', 'background': '#ffffff', 'secondaryColor': '#f5f5f5', 'tertiaryTextColor': '#000', 'actorBkg': '#e3f2fd', 'actorTextColor': '#000', 'actorLineColor': '#1976d2', 'signalColor': '#000', 'signalTextColor': '#000', 'messageLine0': '#1976d2', 'messageLine1': '#1976d2'}}}%%
```

### AudioQueue æ ¸å¿ƒæ¦‚å¿µæ·±åº¦è§£æ

#### 1. AudioQueue å¯¹è±¡ç”Ÿå‘½å‘¨æœŸç®¡ç†

**å®Œæ•´ç”Ÿå‘½å‘¨æœŸçŠ¶æ€æœº**ï¼š
```mermaid
stateDiagram-v2
    [*] --> Uninitialized
    Uninitialized --> Initialized: AudioQueueNewOutput/Input
    Initialized --> Prepared: AudioQueueAllocateBuffer
    Prepared --> Primed: AudioQueuePrime
    Primed --> Running: AudioQueueStart
    Running --> Paused: AudioQueuePause
    Paused --> Running: AudioQueueStart
    Running --> Stopped: AudioQueueStop(false)
    Stopped --> Prepared: AudioQueueReset
    Running --> Disposed: AudioQueueStop(true)
    Stopped --> Disposed: AudioQueueDispose
    Paused --> Disposed: AudioQueueDispose
    Prepared --> Disposed: AudioQueueDispose
    Initialized --> Disposed: AudioQueueDispose
    Disposed --> [*]
    
    note right of Primed : é¢„å¡«å……ç¼“å†²åŒºçŠ¶æ€<br/>ä¼˜åŒ–å¯åŠ¨å»¶è¿Ÿ
    note right of Running : éŸ³é¢‘æ•°æ®æµå¤„ç†çŠ¶æ€<br/>å›è°ƒå‡½æ•°æ´»è·ƒ
    note right of Paused : æš‚åœä½†ä¿æŒæ‰€æœ‰èµ„æº<br/>å¯å¿«é€Ÿæ¢å¤
    note right of Stopped : åœæ­¢å¤„ç†ï¼Œéƒ¨åˆ†èµ„æºé‡Šæ”¾<br/>éœ€è¦é‡æ–°å‡†å¤‡
    note right of Disposed : å®Œå…¨é‡Šæ”¾æ‰€æœ‰èµ„æº<br/>å¯¹è±¡é”€æ¯
```

**çŠ¶æ€è½¬æ¢çš„å†…éƒ¨å®ç°**ï¼š
```c
// AudioQueue å†…éƒ¨çŠ¶æ€ç®¡ç†ç»“æ„
typedef struct {
    AudioQueueState         currentState;          // å½“å‰çŠ¶æ€
    AudioQueueState         previousState;         // å‰ä¸€ä¸ªçŠ¶æ€
    OSSpinLock              stateLock;             // çŠ¶æ€é”
    UInt32                  stateChangeCount;      // çŠ¶æ€å˜æ›´è®¡æ•°
    CFAbsoluteTime          lastStateChangeTime;   // æœ€åçŠ¶æ€å˜æ›´æ—¶é—´
    
    // çŠ¶æ€è½¬æ¢å›è°ƒ
    AudioQueuePropertyListenerProc stateChangeCallback;
    void*                   stateChangeUserData;
    
    // çŠ¶æ€éªŒè¯
    Boolean                 (*stateValidator)(AudioQueueState from, AudioQueueState to);
} AudioQueueStateManager;

// çŠ¶æ€è½¬æ¢å‡½æ•°
OSStatus AudioQueueTransitionToState(AudioQueueRef queue, 
                                     AudioQueueState newState) {
    AudioQueueStateManager *stateManager = queue->stateManager;
    
    // è·å–çŠ¶æ€é”
    OSSpinLockLock(&stateManager->stateLock);
    
    // éªŒè¯çŠ¶æ€è½¬æ¢çš„åˆæ³•æ€§
    if (!stateManager->stateValidator(stateManager->currentState, newState)) {
        OSSpinLockUnlock(&stateManager->stateLock);
        return kAudioQueueErr_InvalidRunState;
    }
    
    // æ‰§è¡ŒçŠ¶æ€è½¬æ¢
    AudioQueueState oldState = stateManager->currentState;
    stateManager->previousState = oldState;
    stateManager->currentState = newState;
    stateManager->stateChangeCount++;
    stateManager->lastStateChangeTime = CFAbsoluteTimeGetCurrent();
    
    OSSpinLockUnlock(&stateManager->stateLock);
    
    // æ‰§è¡ŒçŠ¶æ€ç‰¹å®šçš„æ“ä½œ
    return AudioQueuePerformStateTransition(queue, oldState, newState);
}
```

#### 2. ç¼“å†²åŒºç®¡ç†æœºåˆ¶æ·±åº¦è§£æ

**ç¼“å†²åŒºå†…å­˜å¸ƒå±€**ï¼š
```c
// AudioQueue ç¼“å†²åŒºå®Œæ•´ç»“æ„
typedef struct AudioQueueBuffer {
    // å…¬å…±æ¥å£éƒ¨åˆ†
    const UInt32                mAudioDataBytesCapacity;    // ç¼“å†²åŒºå®¹é‡
    void* const                 mAudioData;                 // éŸ³é¢‘æ•°æ®æŒ‡é’ˆ
    UInt32                      mAudioDataByteSize;         // å®é™…æ•°æ®å¤§å°
    void*                       mUserData;                  // ç”¨æˆ·æ•°æ®
    UInt32                      mPacketDescriptionCapacity; // åŒ…æè¿°å®¹é‡
    AudioStreamPacketDescription* const mPacketDescriptions; // åŒ…æè¿°æ•°ç»„
    UInt32                      mPacketDescriptionCount;    // åŒ…æè¿°æ•°é‡
    
    // å†…éƒ¨å®ç°éƒ¨åˆ†ï¼ˆç³»ç»Ÿç§æœ‰ï¼‰
    struct {
        UInt32              magic;                  // é­”æ³•æ•°å­—ï¼ŒéªŒè¯ç¼“å†²åŒºå®Œæ•´æ€§
        UInt32              version;                // ç‰ˆæœ¬å·
        AudioQueueRef       owner;                  // æ‹¥æœ‰è€…AudioQueue
        UInt32              bufferID;               // ç¼“å†²åŒºå”¯ä¸€ID
        
        // çŠ¶æ€ç®¡ç†
        AudioQueueBufferState state;               // ç¼“å†²åŒºçŠ¶æ€
        UInt32              refCount;               // å¼•ç”¨è®¡æ•°
        CFAbsoluteTime      lastUsedTime;           // æœ€åä½¿ç”¨æ—¶é—´
        
        // æ€§èƒ½ç»Ÿè®¡
        UInt64              totalBytesProcessed;    // æ€»å¤„ç†å­—èŠ‚æ•°
        UInt32              processCount;           // å¤„ç†æ¬¡æ•°
        CFAbsoluteTime      totalProcessTime;       // æ€»å¤„ç†æ—¶é—´
        
        // å†…å­˜ç®¡ç†
        void*               originalPointer;        // åŸå§‹å†…å­˜æŒ‡é’ˆ
        size_t              originalSize;           // åŸå§‹å†…å­˜å¤§å°
        vm_address_t        vmAddress;              // è™šæ‹Ÿå†…å­˜åœ°å€
        vm_size_t           vmSize;                 // è™šæ‹Ÿå†…å­˜å¤§å°
        
        // çº¿ç¨‹åŒæ­¥
        pthread_mutex_t     bufferMutex;            // ç¼“å†²åŒºäº’æ–¥é”
        pthread_cond_t      bufferCondition;        // ç¼“å†²åŒºæ¡ä»¶å˜é‡
        
        // é“¾è¡¨ç®¡ç†
        struct AudioQueueBuffer* next;              // ä¸‹ä¸€ä¸ªç¼“å†²åŒº
        struct AudioQueueBuffer* prev;              // å‰ä¸€ä¸ªç¼“å†²åŒº
    } internal;
} AudioQueueBuffer;

// ç¼“å†²åŒºçŠ¶æ€ç®¡ç†
typedef enum {
    kAudioQueueBufferState_Free = 0,        // ç©ºé—²çŠ¶æ€ï¼Œå¯åˆ†é…
    kAudioQueueBufferState_Allocated,       // å·²åˆ†é…ï¼Œå¾…å¡«å……
    kAudioQueueBufferState_Enqueued,        // å·²å…¥é˜Ÿï¼Œç­‰å¾…å¤„ç†
    kAudioQueueBufferState_Processing,      // å¤„ç†ä¸­ï¼Œåœ¨å›è°ƒå‡½æ•°ä¸­
    kAudioQueueBufferState_Completed,       // å¤„ç†å®Œæˆï¼Œå¾…å›æ”¶
    kAudioQueueBufferState_Error,           // é”™è¯¯çŠ¶æ€ï¼Œéœ€è¦é‡ç½®
    kAudioQueueBufferState_Disposed         // å·²é”€æ¯ï¼Œä¸å¯ä½¿ç”¨
} AudioQueueBufferState;
```

#### 3. é«˜çº§ç¼“å†²åŒºç®¡ç†ç­–ç•¥

**è‡ªé€‚åº”ç¼“å†²åŒºç®¡ç†**ï¼š
```c
// æ™ºèƒ½ç¼“å†²åŒºç®¡ç†å™¨
typedef struct {
    AudioQueueRef               queue;                  // å…³è”çš„AudioQueue
    
    // ç¼“å†²åŒºæ± ç®¡ç†
    AudioQueueBufferRef*        bufferPool;             // ç¼“å†²åŒºæ± 
    UInt32                      poolSize;               // æ± å¤§å°
    UInt32                      activeBuffers;          // æ´»è·ƒç¼“å†²åŒºæ•°
    UInt32                      minimumBuffers;         // æœ€å°ç¼“å†²åŒºæ•°
    UInt32                      maximumBuffers;         // æœ€å¤§ç¼“å†²åŒºæ•°
    
    // åŠ¨æ€è°ƒæ•´å‚æ•°
    UInt32                      targetBufferSize;       // ç›®æ ‡ç¼“å†²åŒºå¤§å°
    UInt32                      currentBufferSize;      // å½“å‰ç¼“å†²åŒºå¤§å°
    Float32                     utilizationRatio;       // åˆ©ç”¨ç‡
    UInt32                      underrunCount;          // æ¬ è½½è®¡æ•°
    UInt32                      overrunCount;           // è¿‡è½½è®¡æ•°
    
    // æ€§èƒ½ç›‘æ§
    CFAbsoluteTime              lastAdjustmentTime;     // æœ€åè°ƒæ•´æ—¶é—´
    UInt32                      adjustmentInterval;     // è°ƒæ•´é—´éš”
    Float32                     avgProcessingTime;      // å¹³å‡å¤„ç†æ—¶é—´
    Float32                     maxProcessingTime;      // æœ€å¤§å¤„ç†æ—¶é—´
    
    // å†…å­˜ç®¡ç†
    vm_address_t                memoryRegion;           // å†…å­˜åŒºåŸŸ
    vm_size_t                   memorySize;             // å†…å­˜å¤§å°
    Boolean                     memoryLocked;           // å†…å­˜æ˜¯å¦é”å®š
    
} AudioQueueBufferManager;

// ç¼“å†²åŒºå¤§å°è‡ªé€‚åº”ç®—æ³•
OSStatus AudioQueueBufferManagerAdjustBufferSize(AudioQueueBufferManager *manager) {
    // è®¡ç®—å½“å‰ç³»ç»Ÿè´Ÿè½½
    Float32 systemLoad = GetSystemAudioLoad();
    
    // è®¡ç®—ç›®æ ‡ç¼“å†²åŒºå¤§å°
    UInt32 targetSize = manager->targetBufferSize;
    
    if (manager->underrunCount > 0) {
        // å‡ºç°æ¬ è½½ï¼Œå¢åŠ ç¼“å†²åŒºå¤§å°
        targetSize = (UInt32)(targetSize * 1.2f);
    } else if (manager->overrunCount > 0 && systemLoad < 0.3f) {
        // å‡ºç°è¿‡è½½ä¸”ç³»ç»Ÿè´Ÿè½½ä½ï¼Œå‡å°‘ç¼“å†²åŒºå¤§å°
        targetSize = (UInt32)(targetSize * 0.8f);
    }
    
    // é™åˆ¶åœ¨åˆç†èŒƒå›´å†…
    targetSize = MAX(1024, MIN(65536, targetSize));
    
    if (targetSize != manager->currentBufferSize) {
        // é‡æ–°åˆ†é…ç¼“å†²åŒº
        return AudioQueueBufferManagerReallocateBuffers(manager, targetSize);
    }
    
    return noErr;
}
```

#### 4. é«˜çº§ç¼“å†²åŒºåŒæ­¥æœºåˆ¶

**é”æ— å…³ç¼“å†²åŒºé˜Ÿåˆ—**ï¼š
```c
// é”æ— å…³ï¼ˆLock-Freeï¼‰ç¼“å†²åŒºé˜Ÿåˆ—å®ç°
typedef struct {
    volatile AudioQueueBufferRef* buffers;      // ç¼“å†²åŒºæ•°ç»„
    volatile UInt32     capacity;               // å®¹é‡
    volatile UInt32     mask;                   // æ©ç ï¼ˆå®¹é‡-1ï¼‰
    
    // åŸå­è®¡æ•°å™¨
    volatile UInt64     enqueueCount;           // å…¥é˜Ÿè®¡æ•°
    volatile UInt64     dequeueCount;           // å‡ºé˜Ÿè®¡æ•°
    
    // å†…å­˜å±éšœ
    volatile UInt32     enqueueBarrier;         // å…¥é˜Ÿå±éšœ
    volatile UInt32     dequeueBarrier;         // å‡ºé˜Ÿå±éšœ
    
} LockFreeAudioQueueBufferQueue;

// é”æ— å…³å…¥é˜Ÿæ“ä½œ
Boolean LockFreeBufferQueueEnqueue(LockFreeAudioQueueBufferQueue* queue, 
                                   AudioQueueBufferRef buffer) {
    UInt64 currentEnqueue = OSAtomicIncrement64(&queue->enqueueCount);
    UInt64 currentDequeue = queue->dequeueCount;
    
    // æ£€æŸ¥é˜Ÿåˆ—æ˜¯å¦å·²æ»¡
    if (currentEnqueue - currentDequeue >= queue->capacity) {
        OSAtomicDecrement64(&queue->enqueueCount);
        return false;
    }
    
    // è®¡ç®—æ’å…¥ä½ç½®
    UInt32 index = (currentEnqueue - 1) & queue->mask;
    
    // ç­‰å¾…ä½ç½®å¯ç”¨
    while (queue->buffers[index] != NULL) {
        sched_yield();
    }
    
    // åŸå­æ€§å†™å…¥
    queue->buffers[index] = buffer;
    
    // å†…å­˜å±éšœç¡®ä¿å†™å…¥å®Œæˆ
    OSMemoryBarrier();
    
    return true;
}

// é”æ— å…³å‡ºé˜Ÿæ“ä½œ
AudioQueueBufferRef LockFreeBufferQueueDequeue(LockFreeAudioQueueBufferQueue* queue) {
    UInt64 currentDequeue = OSAtomicIncrement64(&queue->dequeueCount);
    UInt64 currentEnqueue = queue->enqueueCount;
    
    // æ£€æŸ¥é˜Ÿåˆ—æ˜¯å¦ä¸ºç©º
    if (currentDequeue > currentEnqueue) {
        OSAtomicDecrement64(&queue->dequeueCount);
        return NULL;
    }
    
    // è®¡ç®—è¯»å–ä½ç½®
    UInt32 index = (currentDequeue - 1) & queue->mask;
    
    // ç­‰å¾…æ•°æ®å¯ç”¨
    AudioQueueBufferRef buffer;
    while ((buffer = queue->buffers[index]) == NULL) {
        sched_yield();
    }
    
    // åŸå­æ€§æ¸…é™¤
    queue->buffers[index] = NULL;
    
    // å†…å­˜å±éšœç¡®ä¿è¯»å–å®Œæˆ
    OSMemoryBarrier();
    
    return buffer;
}
```

#### 5. æ—¶é—´æˆ³å’ŒåŒæ­¥æœºåˆ¶

**é«˜ç²¾åº¦æ—¶é—´æˆ³ç®¡ç†**ï¼š
```c
// éŸ³é¢‘æ—¶é—´æˆ³ç®¡ç†ç»“æ„
typedef struct {
    // ç¡¬ä»¶æ—¶é—´æˆ³
    UInt64                  sampleTime;             // é‡‡æ ·æ—¶é—´
    UInt64                  hostTime;               // ä¸»æœºæ—¶é—´
    Float64                 rateScalar;             // é€Ÿç‡æ ‡é‡
    UInt32                  flags;                  // æ ‡å¿—ä½
    
    // è½¯ä»¶æ—¶é—´æˆ³
    CFAbsoluteTime          wallClockTime;          // å¢™ä¸Šæ—¶é’Ÿæ—¶é—´
    UInt64                  machTime;               // Machæ—¶é—´
    UInt64                  audioTimeStamp;         // éŸ³é¢‘æ—¶é—´æˆ³
    
    // åŒæ­¥ä¿¡æ¯
    UInt32                  wordClockTime;          // å­—æ—¶é’Ÿæ—¶é—´
    SMPTETime              smpteTime;              // SMPTEæ—¶é—´ç 
    
    // å»¶è¿Ÿè¡¥å¿
    UInt32                  inputLatency;           // è¾“å…¥å»¶è¿Ÿ
    UInt32                  outputLatency;          // è¾“å‡ºå»¶è¿Ÿ
    UInt32                  processingLatency;      // å¤„ç†å»¶è¿Ÿ
    
} AudioQueueTimeStamp;

// æ—¶é—´æˆ³åŒæ­¥å‡½æ•°
OSStatus AudioQueueSynchronizeTimeStamps(AudioQueueRef queue,
                                         AudioQueueTimeStamp* inputTimestamp,
                                         AudioQueueTimeStamp* outputTimestamp) {
    // è·å–ç¡¬ä»¶æ—¶é—´æˆ³
    AudioTimeStamp hardwareTimestamp;
    UInt32 timestampSize = sizeof(hardwareTimestamp);
    
    OSStatus result = AudioQueueGetProperty(queue,
                                           kAudioQueueProperty_CurrentTime,
                                           &hardwareTimestamp,
                                           &timestampSize);
    if (result != noErr) return result;
    
    // è®¡ç®—å»¶è¿Ÿè¡¥å¿
    UInt64 totalLatency = inputTimestamp->inputLatency + 
                         inputTimestamp->processingLatency + 
                         outputTimestamp->outputLatency;
    
    // åŒæ­¥æ—¶é—´æˆ³
    outputTimestamp->sampleTime = inputTimestamp->sampleTime + totalLatency;
    outputTimestamp->hostTime = inputTimestamp->hostTime + 
                               AudioConvertNanosToHostTime(totalLatency * 1000);
    
    return noErr;
}
```

## æ ¸å¿ƒç»„ä»¶è¯¦è§£

### 1. AudioQueue æ’­æ”¾å™¨å®ç°

#### ä¼ä¸šçº§æ’­æ”¾å™¨æ¶æ„

**å®Œæ•´æ’­æ”¾å™¨æ•°æ®ç»“æ„**ï¼š
```c
// é«˜æ€§èƒ½æ’­æ”¾å™¨çŠ¶æ€ç®¡ç†
typedef struct AQPlayerState {
    // åŸºç¡€éŸ³é¢‘é…ç½®
    AudioStreamBasicDescription   dataFormat;        // éŸ³é¢‘æ ¼å¼
    AudioQueueRef                 queue;             // éŸ³é¢‘é˜Ÿåˆ—
    AudioQueueBufferRef          *buffers;          // ç¼“å†²åŒºæ•°ç»„
    AudioFileID                   audioFile;         // éŸ³é¢‘æ–‡ä»¶ID
    UInt32                        bufferByteSize;    // ç¼“å†²åŒºå¤§å°
    SInt64                        currentPacket;     // å½“å‰åŒ…ä½ç½®
    UInt32                        numPacketsToRead;  // è¯»å–åŒ…æ•°é‡
    AudioStreamPacketDescription *packetDescs;      // åŒ…æè¿°
    
    // çŠ¶æ€ç®¡ç†
    volatile bool                 isRunning;         // è¿è¡ŒçŠ¶æ€
    volatile bool                 isPaused;          // æš‚åœçŠ¶æ€
    volatile bool                 isStopping;        // åœæ­¢ä¸­çŠ¶æ€
    AudioQueuePlayerState         playerState;       // æ’­æ”¾å™¨çŠ¶æ€
    
    // çº¿ç¨‹åŒæ­¥
    pthread_mutex_t               stateMutex;        // çŠ¶æ€äº’æ–¥é”
    pthread_cond_t                stateCondition;    // çŠ¶æ€æ¡ä»¶å˜é‡
    pthread_mutex_t               bufferMutex;       // ç¼“å†²åŒºäº’æ–¥é”
    dispatch_queue_t              callbackQueue;     // å›è°ƒé˜Ÿåˆ—
    dispatch_semaphore_t          bufferSemaphore;   // ç¼“å†²åŒºä¿¡å·é‡
    
    // æ€§èƒ½ç›‘æ§
    UInt64                        totalBytesRead;    // æ€»è¯»å–å­—èŠ‚æ•°
    UInt64                        totalPacketsRead;  // æ€»è¯»å–åŒ…æ•°
    CFAbsoluteTime                startTime;         // å¼€å§‹æ—¶é—´
    CFAbsoluteTime                lastCallbackTime;  // æœ€åå›è°ƒæ—¶é—´
    uint64_t                      maxProcessingTime; // æœ€å¤§å¤„ç†æ—¶é—´
    uint32_t                      underrunCount;     // æ¬ è½½è®¡æ•°
    uint32_t                      callbackCount;     // å›è°ƒè®¡æ•°
    
    // é”™è¯¯å¤„ç†
    OSStatus                      lastError;         // æœ€åé”™è¯¯
    UInt32                        errorCount;        // é”™è¯¯è®¡æ•°
    CFAbsoluteTime                lastErrorTime;     // æœ€åé”™è¯¯æ—¶é—´
    AudioQueueErrorRecoveryState  errorRecovery;     // é”™è¯¯æ¢å¤çŠ¶æ€
    
    // éŸ³é¢‘å¤„ç†
    Float32                       volume;            // éŸ³é‡æ§åˆ¶
    Float32                       rate;              // æ’­æ”¾é€Ÿç‡
    Boolean                       enableTimeScaling; // æ—¶é—´ç¼©æ”¾
    AudioQueueParameterValue      pan;               // å£°é“å¹³ç§»
    
    // ç¼“å­˜ç®¡ç†
    void*                         readAheadBuffer;   // é¢„è¯»ç¼“å†²åŒº
    UInt32                        readAheadSize;     // é¢„è¯»å¤§å°
    SInt64                        endPacket;         // ç»“æŸåŒ…ä½ç½®
    Boolean                       looping;           // å¾ªç¯æ’­æ”¾
    
    // å›è°ƒå‡½æ•°
    AudioQueueOutputCallback      outputCallback;    // è¾“å‡ºå›è°ƒ
    void*                         callbackUserData;  // å›è°ƒç”¨æˆ·æ•°æ®
    
    // å†…å­˜ç®¡ç†
    AudioQueueBufferManager*      bufferManager;     // ç¼“å†²åŒºç®¡ç†å™¨
    MemoryPool*                   memoryPool;        // å†…å­˜æ± 
    
} AQPlayerState;

// æ’­æ”¾å™¨çŠ¶æ€æšä¸¾
typedef enum {
    kAudioQueuePlayerState_Uninitialized = 0,
    kAudioQueuePlayerState_Initialized,
    kAudioQueuePlayerState_Prepared,
    kAudioQueuePlayerState_Playing,
    kAudioQueuePlayerState_Paused,
    kAudioQueuePlayerState_Stopped,
    kAudioQueuePlayerState_Error,
    kAudioQueuePlayerState_Disposed
} AudioQueuePlayerState;

// ä¼ä¸šçº§æ’­æ”¾å™¨åˆå§‹åŒ–
OSStatus CreateAudioQueuePlayer(AQPlayerState *aqData, 
                                CFURLRef inFileURL,
                                const AudioQueuePlayerConfig *config) {
    OSStatus result = noErr;
    
    // å‚æ•°éªŒè¯
    if (!aqData || !inFileURL) {
        return kAudioQueueErr_InvalidParameter;
    }
    
    // åˆå§‹åŒ–çŠ¶æ€
    memset(aqData, 0, sizeof(AQPlayerState));
    aqData->playerState = kAudioQueuePlayerState_Uninitialized;
    aqData->volume = 1.0f;
    aqData->rate = 1.0f;
    aqData->pan = 0.0f;
    
    // åˆå§‹åŒ–çº¿ç¨‹åŒæ­¥åŸè¯­
    result = InitializePlayerSyncPrimitives(aqData);
    if (result != noErr) {
        goto cleanup;
    }
    
    // 1. æ‰“å¼€éŸ³é¢‘æ–‡ä»¶ï¼ˆå¸¦é”™è¯¯æ¢å¤ï¼‰
    result = AudioFileOpenURL(inFileURL, kAudioFileReadPermission, 0, &aqData->audioFile);
    if (result != noErr) {
        LogAudioError("Failed to open audio file", result);
        goto cleanup;
    }
    
    // 2. è·å–å¹¶éªŒè¯éŸ³é¢‘æ ¼å¼ä¿¡æ¯
    UInt32 dataFormatSize = sizeof(aqData->dataFormat);
    result = AudioFileGetProperty(aqData->audioFile, 
                                 kAudioFilePropertyDataFormat,
                                 &dataFormatSize, 
                                 &aqData->dataFormat);
    if (result != noErr) {
        LogAudioError("Failed to get audio format", result);
        goto cleanup;
    }
    
    // éªŒè¯éŸ³é¢‘æ ¼å¼æ”¯æŒ
    result = ValidateAudioFormat(&aqData->dataFormat);
    if (result != noErr) {
        LogAudioError("Unsupported audio format", result);
        goto cleanup;
    }
    
    // 3. åˆ›å»ºé«˜æ€§èƒ½æ’­æ”¾é˜Ÿåˆ—
    result = AudioQueueNewOutput(&aqData->dataFormat,
                                HandleOutputBufferWithErrorRecovery,
                                aqData,
                                NULL,  // ä½¿ç”¨ä¸“ç”¨çº¿ç¨‹è€ŒéRunLoop
                                NULL,
                                0,
                                &aqData->queue);
    if (result != noErr) {
        LogAudioError("Failed to create audio queue", result);
        goto cleanup;
    }
    
    // è®¾ç½®å®æ—¶ä¼˜å…ˆçº§
    result = ConfigureRealtimeAudioThread(aqData->queue);
    if (result != noErr) {
        NSLog(@"Warning: Failed to set realtime priority: %d", (int)result);
    }
    
    // 4. æ™ºèƒ½ç¼“å†²åŒºå¤§å°è®¡ç®—
    result = CalculateOptimalBufferConfiguration(aqData, config);
    if (result != noErr) {
        LogAudioError("Failed to calculate buffer configuration", result);
        goto cleanup;
    }
    
    // 5. åˆå§‹åŒ–ç¼“å†²åŒºç®¡ç†å™¨
    aqData->bufferManager = CreateAudioQueueBufferManager(aqData->queue,
                                                          aqData->bufferByteSize,
                                                          kNumAQBufs);
    if (!aqData->bufferManager) {
        result = kAudioQueueErr_MemoryFailure;
        goto cleanup;
    }
    
    // åˆ†é…éŸ³é¢‘ç¼“å†²åŒº
    aqData->buffers = (AudioQueueBufferRef*)calloc(kNumAQBufs, sizeof(AudioQueueBufferRef));
    for (int i = 0; i < kNumAQBufs; ++i) {
        result = AudioQueueAllocateBuffer(aqData->queue, 
                                         aqData->bufferByteSize, 
                                         &aqData->buffers[i]);
        if (result != noErr) {
            LogAudioError("Failed to allocate buffer", result);
            goto cleanup;
        }
        
        // æ ‡è®°ç¼“å†²åŒºç”¨æˆ·æ•°æ®
        aqData->buffers[i]->mUserData = aqData;
    }
    
    // 6. è®¾ç½®éŸ³é¢‘é˜Ÿåˆ—å±æ€§
    result = ConfigureAudioQueueProperties(aqData, config);
    if (result != noErr) {
        LogAudioError("Failed to configure audio queue properties", result);
        goto cleanup;
    }
    
    // 7. åˆå§‹åŒ–æ€§èƒ½ç›‘æ§
    aqData->startTime = CFAbsoluteTimeGetCurrent();
    aqData->maxProcessingTime = AudioConvertHostTimeToNanos(1000000); // 1msé˜ˆå€¼
    
    // 8. è·å–æ–‡ä»¶æ€»é•¿åº¦ä¿¡æ¯
    result = GetAudioFileInfo(aqData);
    if (result != noErr) {
        LogAudioError("Failed to get audio file info", result);
        goto cleanup;
    }
    
    // 9. åˆ›å»ºå›è°ƒé˜Ÿåˆ—
    aqData->callbackQueue = dispatch_queue_create("com.audioqueue.callback", 
                                                  DISPATCH_QUEUE_SERIAL);
    dispatch_set_target_queue(aqData->callbackQueue, 
                             dispatch_get_global_queue(DISPATCH_QUEUE_PRIORITY_HIGH, 0));
    
    // 10. åˆå§‹åŒ–å†…å­˜æ± 
    aqData->memoryPool = CreateMemoryPool(aqData->bufferByteSize * kNumAQBufs * 2);
    
    aqData->playerState = kAudioQueuePlayerState_Initialized;
    return noErr;
    
cleanup:
    CleanupAudioQueuePlayer(aqData);
    return result;
}

// é…ç½®æ’­æ”¾å™¨ç»“æ„
typedef struct {
    Float32     bufferDurationSeconds;    // ç¼“å†²åŒºæŒç»­æ—¶é—´
    UInt32      minimumBuffers;           // æœ€å°ç¼“å†²åŒºæ•°é‡
    UInt32      maximumBuffers;           // æœ€å¤§ç¼“å†²åŒºæ•°é‡
    Boolean     enableLowLatencyMode;     // å¯ç”¨ä½å»¶è¿Ÿæ¨¡å¼
    Boolean     enablePerformanceMonitoring; // å¯ç”¨æ€§èƒ½ç›‘æ§
    Float32     volumeRampDuration;       // éŸ³é‡æ¸å˜æŒç»­æ—¶é—´
    AudioQueuePlayerQuality quality;      // æ’­æ”¾è´¨é‡çº§åˆ«
} AudioQueuePlayerConfig;

// æ™ºèƒ½ç¼“å†²åŒºé…ç½®è®¡ç®—
OSStatus CalculateOptimalBufferConfiguration(AQPlayerState *aqData, 
                                            const AudioQueuePlayerConfig *config) {
    // åŸºç¡€ç¼“å†²åŒºå¤§å°è®¡ç®—
    Float32 bufferDuration = config ? config->bufferDurationSeconds : 0.5f;
    
    // æ ¹æ®è®¾å¤‡æ€§èƒ½å’ŒéŸ³é¢‘æ ¼å¼è°ƒæ•´
    if (config && config->enableLowLatencyMode) {
        bufferDuration = MIN(bufferDuration, 0.1f); // ä½å»¶è¿Ÿæ¨¡å¼æœ€å¤§100ms
    }
    
    // è®¡ç®—æ ·æœ¬æ•°å’Œå­—èŠ‚æ•°
    UInt32 samplesPerBuffer = (UInt32)(aqData->dataFormat.mSampleRate * bufferDuration);
    aqData->bufferByteSize = samplesPerBuffer * aqData->dataFormat.mBytesPerFrame;
    
    // å¯¹é½åˆ°é¡µè¾¹ç•Œ
    UInt32 pageSize = getpagesize();
    aqData->bufferByteSize = (aqData->bufferByteSize + pageSize - 1) & ~(pageSize - 1);
    
    // è®¡ç®—æ¯ä¸ªç¼“å†²åŒºçš„åŒ…æ•°
    if (aqData->dataFormat.mFramesPerPacket > 0) {
        aqData->numPacketsToRead = samplesPerBuffer / aqData->dataFormat.mFramesPerPacket;
    } else {
        // VBRæ ¼å¼çš„ä¼°ç®—
        aqData->numPacketsToRead = samplesPerBuffer;
    }
    
    // ä¸ºVBRæ ¼å¼åˆ†é…åŒ…æè¿°æ•°ç»„
    if (aqData->dataFormat.mFramesPerPacket == 0) {
        aqData->packetDescs = (AudioStreamPacketDescription*)
            malloc(aqData->numPacketsToRead * sizeof(AudioStreamPacketDescription));
        if (!aqData->packetDescs) {
            return kAudioQueueErr_MemoryFailure;
        }
    }
    
    return noErr;
}

// éŸ³é¢‘é˜Ÿåˆ—å±æ€§é…ç½®
OSStatus ConfigureAudioQueueProperties(AQPlayerState *aqData, 
                                       const AudioQueuePlayerConfig *config) {
    OSStatus result = noErr;
    
    // è®¾ç½®éŸ³é‡
    result = AudioQueueSetParameter(aqData->queue, kAudioQueueParam_Volume, aqData->volume);
    if (result != noErr) return result;
    
    // è®¾ç½®å£°é“å¹³ç§»
    result = AudioQueueSetParameter(aqData->queue, kAudioQueueParam_Pan, aqData->pan);
    if (result != noErr) return result;
    
    // å¯ç”¨æ—¶é—´æ‹‰ä¼¸ï¼ˆå¦‚æœæ”¯æŒï¼‰
    if (config && config->quality >= kAudioQueuePlayerQuality_High) {
        UInt32 enableTimePitch = 1;
        AudioQueueSetProperty(aqData->queue,
                             kAudioQueueProperty_EnableTimePitch,
                             &enableTimePitch,
                             sizeof(enableTimePitch));
    }
    
    // è®¾ç½®æ’­æ”¾é€Ÿç‡
    if (aqData->rate != 1.0f) {
        result = AudioQueueSetParameter(aqData->queue, kAudioQueueParam_PlayRate, aqData->rate);
        if (result != noErr) return result;
    }
    
    // é…ç½®éŸ³é¢‘è´¨é‡
    if (config) {
        UInt32 qualityLevel = config->quality;
        AudioQueueSetProperty(aqData->queue,
                             kAudioQueueProperty_CodecQuality,
                             &qualityLevel,
                             sizeof(qualityLevel));
    }
    
    return noErr;
}
```

#### ä¼ä¸šçº§é«˜æ€§èƒ½æ’­æ”¾å›è°ƒ

**å¸¦é”™è¯¯æ¢å¤çš„éŸ³é¢‘å›è°ƒ**ï¼š
```c
// é«˜æ€§èƒ½éŸ³é¢‘è¾“å‡ºå›è°ƒå‡½æ•°ï¼ˆä¼ä¸šçº§ï¼‰
void HandleOutputBufferWithErrorRecovery(void                 *userData,
                                        AudioQueueRef        audioQueue,
                                        AudioQueueBufferRef  buffer) {
    AQPlayerState *playerState = (AQPlayerState *)userData;
    
    // å¿«é€ŸçŠ¶æ€æ£€æŸ¥ - åŸå­æ“ä½œï¼Œæœ€å°å¼€é”€
    if (!playerState->isRunning || playerState->isStopping) {
        return;
    }
    
    // æ€§èƒ½ç›‘æ§å¼€å§‹
    uint64_t callbackStartTime = mach_absolute_time();
    ++playerState->callbackCount;
    
    // é”™è¯¯æ¢å¤æ£€æŸ¥
    if (playerState->playerState == kAudioQueuePlayerState_Error) {
        if (AttemptErrorRecovery(playerState) != noErr) {
            return;
        }
    }
    
    // æ‰§è¡Œä¸»è¦éŸ³é¢‘å¤„ç†
    OSStatus result = ProcessAudioBuffer(playerState, audioQueue, buffer);
    
    // æ€§èƒ½ç›‘æ§ç»“æŸ
    uint64_t callbackEndTime = mach_absolute_time();
    uint64_t processingTime = callbackEndTime - callbackStartTime;
    
    // æ›´æ–°æ€§èƒ½ç»Ÿè®¡
    UpdatePerformanceStatistics(playerState, processingTime);
    
    // é”™è¯¯å¤„ç†
    if (result != noErr) {
        HandleCallbackError(playerState, result, buffer);
    }
}

// ä¸»è¦éŸ³é¢‘å¤„ç†å‡½æ•°
OSStatus ProcessAudioBuffer(AQPlayerState *playerState,
                           AudioQueueRef audioQueue,
                           AudioQueueBufferRef buffer) {
    OSStatus result = noErr;
    UInt32 numBytesRead = 0;
    UInt32 numPacketsToRead = playerState->numPacketsToRead;
    UInt32 numPacketsRead = numPacketsToRead;
    
    // æ£€æŸ¥æ˜¯å¦åˆ°è¾¾æ–‡ä»¶æœ«å°¾
    if (playerState->currentPacket >= playerState->endPacket) {
        if (playerState->looping) {
            // å¾ªç¯æ’­æ”¾ - é‡ç½®åˆ°å¼€å§‹ä½ç½®
            playerState->currentPacket = 0;
            result = AudioFileSeek(playerState->audioFile, 0, &playerState->currentPacket);
            if (result != noErr) {
                return result;
            }
        } else {
            // æ’­æ”¾ç»“æŸ
            return HandlePlaybackCompletion(playerState);
        }
    }
    
    // ä½¿ç”¨é«˜æ€§èƒ½æ–‡ä»¶è¯»å–
    result = PerformOptimizedFileRead(playerState, 
                                     buffer, 
                                     &numBytesRead, 
                                     &numPacketsRead);
    
    if (result != noErr) {
        LogAudioError("File read error", result);
        return result;
    }
    
    if (numPacketsRead > 0) {
        // è®¾ç½®ç¼“å†²åŒºæ•°æ®å¤§å°
        buffer->mAudioDataByteSize = numBytesRead;
        
        // åº”ç”¨å®æ—¶éŸ³é¢‘æ•ˆæœï¼ˆå¦‚æœéœ€è¦ï¼‰
        if (playerState->volume != 1.0f || playerState->rate != 1.0f) {
            ApplyRealtimeEffects(playerState, buffer);
        }
        
        // å…¥é˜Ÿç¼“å†²åŒº
        result = EnqueueBufferWithRetry(audioQueue, buffer, numPacketsRead, playerState);
        
        // æ›´æ–°æ’­æ”¾ä½ç½®
        playerState->currentPacket += numPacketsRead;
        playerState->totalBytesRead += numBytesRead;
        playerState->totalPacketsRead += numPacketsRead;
        
    } else {
        // æ²¡æœ‰è¯»å–åˆ°æ•°æ®ï¼Œå¯èƒ½æ˜¯æ–‡ä»¶ç»“æŸ
        return HandlePlaybackCompletion(playerState);
    }
    
    return result;
}

// ä¼˜åŒ–çš„æ–‡ä»¶è¯»å–å‡½æ•°
OSStatus PerformOptimizedFileRead(AQPlayerState *playerState,
                                 AudioQueueBufferRef buffer,
                                 UInt32 *outBytesRead,
                                 UInt32 *outPacketsRead) {
    OSStatus result = noErr;
    
    // ä½¿ç”¨é¢„è¯»ç¼“å†²åŒºï¼ˆå¦‚æœå¯ç”¨ï¼‰
    if (playerState->readAheadBuffer && playerState->readAheadSize > 0) {
        result = ReadFromPreBuffer(playerState, buffer, outBytesRead, outPacketsRead);
    } else {
        // ç›´æ¥ä»æ–‡ä»¶è¯»å–
        result = AudioFileReadPacketData(playerState->audioFile,
                                        false,  // ä¸ä½¿ç”¨ç¼“å­˜
                                        outBytesRead,
                                        playerState->packetDescs,
                                        playerState->currentPacket,
                                        outPacketsRead,
                                        buffer->mAudioData);
    }
    
    // æ£€æŸ¥è¯»å–ç»“æœ
    if (result == kAudioFileEndOfFileError) {
        // æ–‡ä»¶ç»“æŸæ˜¯æ­£å¸¸æƒ…å†µ
        result = noErr;
        *outPacketsRead = 0;
    } else if (result != noErr) {
        // å…¶ä»–é”™è¯¯éœ€è¦å¤„ç†
        ++playerState->errorCount;
        playerState->lastError = result;
        playerState->lastErrorTime = CFAbsoluteTimeGetCurrent();
    }
    
    return result;
}

// å®æ—¶éŸ³é¢‘æ•ˆæœå¤„ç†
void ApplyRealtimeEffects(AQPlayerState *playerState, AudioQueueBufferRef buffer) {
    if (playerState->dataFormat.mFormatID != kAudioFormatLinearPCM) {
        return; // åªæ”¯æŒPCMæ ¼å¼çš„å®æ—¶å¤„ç†
    }
    
    Float32 *audioData = (Float32 *)buffer->mAudioData;
    UInt32 frameCount = buffer->mAudioDataByteSize / playerState->dataFormat.mBytesPerFrame;
    UInt32 channelCount = playerState->dataFormat.mChannelsPerFrame;
    
    // éŸ³é‡è°ƒæ•´
    if (playerState->volume != 1.0f) {
        for (UInt32 frame = 0; frame < frameCount; frame++) {
            for (UInt32 channel = 0; channel < channelCount; channel++) {
                audioData[frame * channelCount + channel] *= playerState->volume;
            }
        }
    }
    
    // å£°é“å¹³ç§»ï¼ˆç«‹ä½“å£°ï¼‰
    if (channelCount == 2 && playerState->pan != 0.0f) {
        Float32 leftGain = 1.0f - MAX(0.0f, playerState->pan);
        Float32 rightGain = 1.0f + MIN(0.0f, playerState->pan);
        
        for (UInt32 frame = 0; frame < frameCount; frame++) {
            audioData[frame * 2] *= leftGain;     // å·¦å£°é“
            audioData[frame * 2 + 1] *= rightGain; // å³å£°é“
        }
    }
}

// å¸¦é‡è¯•çš„ç¼“å†²åŒºå…¥é˜Ÿ
OSStatus EnqueueBufferWithRetry(AudioQueueRef audioQueue,
                               AudioQueueBufferRef buffer,
                               UInt32 packetCount,
                               AQPlayerState *playerState) {
    OSStatus result;
    int retryCount = 0;
    const int maxRetries = 3;
    
    do {
        if (playerState->packetDescs) {
            result = AudioQueueEnqueueBuffer(audioQueue, buffer, packetCount, playerState->packetDescs);
        } else {
            result = AudioQueueEnqueueBuffer(audioQueue, buffer, 0, NULL);
        }
        
        if (result == noErr) {
            break;
        }
        
        // é‡è¯•å‰çš„ç­‰å¾…å’Œé”™è¯¯åˆ†æ
        if (result == kAudioQueueErr_BufferInUse) {
            // ç¼“å†²åŒºä»åœ¨ä½¿ç”¨ä¸­ï¼ŒçŸ­æš‚ç­‰å¾…
            usleep(100); // 100å¾®ç§’
        } else if (result == kAudioQueueErr_InvalidRunState) {
            // é˜Ÿåˆ—çŠ¶æ€æ— æ•ˆï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦é‡å¯
            if (playerState->isRunning) {
                result = RestartAudioQueue(playerState);
                if (result != noErr) {
                    break;
                }
            } else {
                break; // ç”¨æˆ·åœæ­¢æ’­æ”¾
            }
        }
        
        retryCount++;
        
    } while (retryCount < maxRetries);
    
    if (result != noErr && retryCount >= maxRetries) {
        LogAudioError("Failed to enqueue buffer after retries", result);
        ++playerState->errorCount;
    }
    
    return result;
}

// æ’­æ”¾å®Œæˆå¤„ç†
OSStatus HandlePlaybackCompletion(AQPlayerState *playerState) {
    // è®¾ç½®åœæ­¢çŠ¶æ€
    playerState->isRunning = false;
    playerState->playerState = kAudioQueuePlayerState_Stopped;
    
    // é€šçŸ¥åº”ç”¨ç¨‹åºæ’­æ”¾å®Œæˆ
    if (playerState->outputCallback) {
        dispatch_async(playerState->callbackQueue, ^{
            // åœ¨å›è°ƒé˜Ÿåˆ—ä¸­é€šçŸ¥
            NotifyPlaybackCompletion(playerState);
        });
    }
    
    // åœæ­¢éŸ³é¢‘é˜Ÿåˆ—
    OSStatus result = AudioQueueStop(playerState->queue, false);
    if (result != noErr) {
        LogAudioError("Failed to stop audio queue", result);
    }
    
    return kAudioFileEndOfFileError; // è¡¨ç¤ºæ­£å¸¸ç»“æŸ
}

// æ€§èƒ½ç»Ÿè®¡æ›´æ–°
void UpdatePerformanceStatistics(AQPlayerState *playerState, uint64_t processingTime) {
    // æ›´æ–°æœ€åå›è°ƒæ—¶é—´
    CFAbsoluteTime currentTime = CFAbsoluteTimeGetCurrent();
    playerState->lastCallbackTime = currentTime;
    
    // æ£€æŸ¥å¤„ç†æ—¶é—´æ˜¯å¦è¶…è¿‡é˜ˆå€¼
    if (processingTime > playerState->maxProcessingTime) {
        // è®°å½•æ€§èƒ½è­¦å‘Š
        uint64_t processingNanos = AudioConvertHostTimeToNanos(processingTime);
        NSLog(@"Audio callback performance warning: %llu ns (threshold: %llu ns)", 
              processingNanos, AudioConvertHostTimeToNanos(playerState->maxProcessingTime));
        
        // å¢åŠ æ¬ è½½è®¡æ•°
        ++playerState->underrunCount;
    }
    
    // è®¡ç®—å›è°ƒé—´éš”
    static CFAbsoluteTime lastUpdateTime = 0;
    if (lastUpdateTime > 0) {
        CFAbsoluteTime interval = currentTime - lastUpdateTime;
        // æ£€æŸ¥æ˜¯å¦æœ‰è·³è·ƒï¼ˆå¯èƒ½çš„æ¬ è½½ï¼‰
        Float64 expectedInterval = (Float64)playerState->numPacketsToRead / playerState->dataFormat.mSampleRate;
        if (interval > expectedInterval * 1.5) {
            ++playerState->underrunCount;
        }
    }
    lastUpdateTime = currentTime;
}

// å›è°ƒé”™è¯¯å¤„ç†
void HandleCallbackError(AQPlayerState *playerState, OSStatus error, AudioQueueBufferRef buffer) {
    playerState->lastError = error;
    playerState->lastErrorTime = CFAbsoluteTimeGetCurrent();
    ++playerState->errorCount;
    
    // æ ¹æ®é”™è¯¯ç±»å‹å†³å®šå¤„ç†ç­–ç•¥
    switch (error) {
        case kAudioFileEndOfFileError:
            // æ–‡ä»¶ç»“æŸï¼Œæ­£å¸¸æƒ…å†µ
            HandlePlaybackCompletion(playerState);
            break;
            
        case kAudioQueueErr_BufferEmpty:
            // ç¼“å†²åŒºç©ºï¼Œå°è¯•é‡æ–°å¡«å……
            ++playerState->underrunCount;
            break;
            
        case kAudioQueueErr_InvalidBuffer:
            // æ— æ•ˆç¼“å†²åŒºï¼Œå°è¯•é‡æ–°åˆ†é…
            ReallocateAudioBuffer(playerState, buffer);
            break;
            
        default:
            // å…¶ä»–é”™è¯¯ï¼Œè¿›å…¥é”™è¯¯çŠ¶æ€
            playerState->playerState = kAudioQueuePlayerState_Error;
            LogAudioError("Callback error", error);
            break;
    }
}
```

### 2. AudioQueue å½•éŸ³å™¨å®ç°

#### ä¸“ä¸šå½•éŸ³æ¶æ„

```c
// å½•éŸ³å™¨æ•°æ®ç»“æ„
typedef struct AQRecorderState {
    AudioStreamBasicDescription  dataFormat;         // å½•éŸ³æ ¼å¼
    AudioQueueRef                queue;              // å½•éŸ³é˜Ÿåˆ—
    AudioQueueBufferRef         *buffers;           // ç¼“å†²åŒºæ•°ç»„
    AudioFileID                  audioFile;          // è¾“å‡ºæ–‡ä»¶
    UInt32                       bufferByteSize;     // ç¼“å†²åŒºå¤§å°
    SInt64                       currentPacket;      // å½“å‰åŒ…ä½ç½®
    bool                         isRunning;          // å½•éŸ³çŠ¶æ€
    
    // é«˜çº§å½•éŸ³åŠŸèƒ½
    AudioQueueLevelMeterState   *levelMeterState;    // éŸ³é‡ç›‘æ§
    Float32                      recordVolume;       // å½•éŸ³éŸ³é‡
    UInt32                       channelCount;       // å£°é“æ•°
    
    // æ€§èƒ½ç›‘æ§
    uint64_t                     totalSamples;       // æ€»é‡‡æ ·æ•°
    uint64_t                     droppedSamples;     // ä¸¢å¤±é‡‡æ ·æ•°
    CFAbsoluteTime               startTime;          // å¼€å§‹æ—¶é—´
    
    // çº¿ç¨‹åŒæ­¥
    dispatch_queue_t             recordQueue;        // å½•éŸ³é˜Ÿåˆ—
    dispatch_semaphore_t         bufferSemaphore;    // ç¼“å†²åŒºä¿¡å·é‡
} AQRecorderState;

// å½•éŸ³å™¨åˆå§‹åŒ–
OSStatus CreateAudioQueueRecorder(AQRecorderState *aqData, 
                                  CFURLRef outputFileURL,
                                  AudioStreamBasicDescription *recordFormat) {
    OSStatus result = noErr;
    
    // 1. è®¾ç½®å½•éŸ³æ ¼å¼
    if (recordFormat == NULL) {
        // ä½¿ç”¨é»˜è®¤é«˜è´¨é‡å½•éŸ³æ ¼å¼
        aqData->dataFormat.mSampleRate = 44100.0;
        aqData->dataFormat.mFormatID = kAudioFormatLinearPCM;
        aqData->dataFormat.mFormatFlags = kLinearPCMFormatFlagIsBigEndian
                                        | kLinearPCMFormatFlagIsSignedInteger
                                        | kLinearPCMFormatFlagIsPacked;
        aqData->dataFormat.mBytesPerPacket = 4;
        aqData->dataFormat.mFramesPerPacket = 1;
        aqData->dataFormat.mBytesPerFrame = 4;
        aqData->dataFormat.mChannelsPerFrame = 2;
        aqData->dataFormat.mBitsPerChannel = 16;
    } else {
        aqData->dataFormat = *recordFormat;
    }
    
    // 2. åˆ›å»ºå½•éŸ³é˜Ÿåˆ—
    result = AudioQueueNewInput(&aqData->dataFormat,
                               HandleInputBuffer,
                               aqData,
                               NULL,
                               kCFRunLoopCommonModes,
                               0,
                               &aqData->queue);
    if (result != noErr) return result;
    
    // 3. è·å–å®é™…æ ¼å¼ï¼ˆç³»ç»Ÿå¯èƒ½è°ƒæ•´æ ¼å¼ï¼‰
    UInt32 dataFormatSize = sizeof(aqData->dataFormat);
    AudioQueueGetProperty(aqData->queue,
                         kAudioQueueProperty_StreamDescription,
                         &aqData->dataFormat,
                         &dataFormatSize);
    
    // 4. åˆ›å»ºéŸ³é¢‘æ–‡ä»¶
    result = AudioFileCreateWithURL(outputFileURL,
                                   kAudioFileAIFFType,
                                   &aqData->dataFormat,
                                   kAudioFileFlags_EraseFile,
                                   &aqData->audioFile);
    if (result != noErr) return result;
    
    // 5. è®¡ç®—ç¼“å†²åŒºå¤§å°ï¼ˆä½å»¶è¿Ÿä¼˜åŒ–ï¼‰
    DeriveBufferSize(aqData->queue,
                     &aqData->dataFormat,
                     0.1,  // 0.1ç§’ç¼“å†²ï¼ˆä½å»¶è¿Ÿï¼‰
                     &aqData->bufferByteSize);
    
    // 6. åˆ†é…ç¼“å†²åŒº
    for (int i = 0; i < kNumAQBufs; ++i) {
        result = AudioQueueAllocateBuffer(aqData->queue,
                                         aqData->bufferByteSize,
                                         &aqData->buffers[i]);
        if (result != noErr) return result;
        
        // ç«‹å³å…¥é˜Ÿç¼“å†²åŒº
        AudioQueueEnqueueBuffer(aqData->queue, aqData->buffers[i], 0, NULL);
    }
    
    // 7. å¯ç”¨éŸ³é‡ç›‘æ§
    UInt32 enableLevelMeter = 1;
    AudioQueueSetProperty(aqData->queue,
                         kAudioQueueProperty_EnableLevelMetering,
                         &enableLevelMeter,
                         sizeof(enableLevelMeter));
    
    // 8. åˆå§‹åŒ–æ€§èƒ½ç›‘æ§
    aqData->totalSamples = 0;
    aqData->droppedSamples = 0;
    aqData->startTime = CFAbsoluteTimeGetCurrent();
    
    // 9. åˆ›å»ºå½•éŸ³é˜Ÿåˆ—å’Œä¿¡å·é‡
    aqData->recordQueue = dispatch_queue_create("com.audio.record", DISPATCH_QUEUE_SERIAL);
    aqData->bufferSemaphore = dispatch_semaphore_create(kNumAQBufs);
    
    return noErr;
}

// é«˜æ€§èƒ½å½•éŸ³å›è°ƒ
void HandleInputBuffer(void                 *aqData,
                      AudioQueueRef        inAQ,
                      AudioQueueBufferRef  inBuffer,
                      const AudioTimeStamp *inStartTime,
                      UInt32               inNumPackets,
                      const AudioStreamPacketDescription *inPacketDesc) {
    
    AQRecorderState *pAqData = (AQRecorderState *)aqData;
    
    // å¿«é€ŸçŠ¶æ€æ£€æŸ¥
    if (inNumPackets == 0 && inPacketDesc != NULL) {
        inNumPackets = inBuffer->mAudioDataByteSize / pAqData->dataFormat.mBytesPerPacket;
    }
    
    if (inNumPackets > 0) {
        // å¼‚æ­¥å†™å…¥æ–‡ä»¶ï¼ˆé¿å…é˜»å¡éŸ³é¢‘çº¿ç¨‹ï¼‰
        dispatch_async(pAqData->recordQueue, ^{
            OSStatus result = AudioFileWritePackets(pAqData->audioFile,
                                                   false,
                                                   inBuffer->mAudioDataByteSize,
                                                   inPacketDesc,
                                                   pAqData->currentPacket,
                                                   &inNumPackets,
                                                   inBuffer->mAudioData);
            
            if (result == noErr) {
                pAqData->currentPacket += inNumPackets;
                pAqData->totalSamples += inNumPackets;
            } else {
                pAqData->droppedSamples += inNumPackets;
                NSLog(@"Audio write error: %d", (int)result);
            }
            
            // é‡Šæ”¾ä¿¡å·é‡
            dispatch_semaphore_signal(pAqData->bufferSemaphore);
        });
        
        // ç­‰å¾…ç¼“å†²åŒºå¯ç”¨
        dispatch_semaphore_wait(pAqData->bufferSemaphore, DISPATCH_TIME_FOREVER);
    }
    
    // é‡æ–°å…¥é˜Ÿç¼“å†²åŒº
    if (pAqData->isRunning) {
        AudioQueueEnqueueBuffer(pAqData->queue, inBuffer, 0, NULL);
    }
}
```

## åº•æ—¶å»¶ä¼˜åŒ–æ·±åº¦å®ç°

### 1. å»¶è¿Ÿæ¥æºåˆ†æä¸ä¼˜åŒ–

#### ç³»ç»Ÿçº§å»¶è¿Ÿåˆ†æ

```mermaid
flowchart TD
    subgraph "ç¡¬ä»¶å±‚å»¶è¿Ÿ"
        A[éŸ³é¢‘è¾“å…¥] --> B[ADCè½¬æ¢<br/>~0.05-0.1ms]
        B --> C[æ¨¡æ‹Ÿæ»¤æ³¢<br/>~0.02ms]
    end
    
    subgraph "é©±åŠ¨å±‚å»¶è¿Ÿ"
        C --> D[I/O Kité©±åŠ¨<br/>~0.3-0.5ms]
        D --> E[HALç¼“å†²<br/>~0.2-0.8ms]
        E --> F[å†…æ ¸è°ƒåº¦<br/>~0.1-0.3ms]
    end
    
    subgraph "AudioQueueå±‚å»¶è¿Ÿ"
        F --> G[è¾“å…¥ç¼“å†²<br/>å¯é…ç½® 2-20ms]
        G --> H[æ ¼å¼è½¬æ¢<br/>~0.1-0.5ms]
        H --> I[å›è°ƒå¤„ç†<br/>ç”¨æˆ·ä»£ç ]
        I --> J[è¾“å‡ºç¼“å†²<br/>å¯é…ç½® 2-20ms]
    end
    
    subgraph "ç¡¬ä»¶è¾“å‡ºå»¶è¿Ÿ"
        J --> K[HALè¾“å‡º<br/>~0.2-0.8ms]
        K --> L[é©±åŠ¨è¾“å‡º<br/>~0.3-0.5ms]
        L --> M[DACè½¬æ¢<br/>~0.05-0.1ms]
        M --> N[éŸ³é¢‘è¾“å‡º]
    end
    
    style G fill:#ffeb3b,stroke:#f57c00,stroke-width:2px,color:#000
    style I fill:#ff9800,stroke:#ef6c00,stroke-width:2px,color:#000
    style J fill:#ffeb3b,stroke:#f57c00,stroke-width:2px,color:#000
    style A fill:#e3f2fd,color:#000
    style B fill:#e8f5e8,color:#000
    style C fill:#e8f5e8,color:#000
    style D fill:#fff3e0,color:#000
    style E fill:#fff3e0,color:#000
    style F fill:#fff3e0,color:#000
    style H fill:#ffeb3b,color:#000
    style K fill:#f3e5f5,color:#000
    style L fill:#f3e5f5,color:#000
    style M fill:#f3e5f5,color:#000
    style N fill:#fce4ec,color:#000
    
    O[æ€»å»¶è¿Ÿè®¡ç®—] --> P[ç¡¬ä»¶: 0.14-0.24ms<br/>é©±åŠ¨: 0.8-1.6ms<br/>AudioQueue: 4-40ms<br/>æ€»è®¡: 4.94-41.84ms]
    
    style O fill:#e3f2fd,color:#000
    style P fill:#e8f5e8,color:#000
```

#### å»¶è¿Ÿä¼˜åŒ–ç›®æ ‡çŸ©é˜µ

| åº”ç”¨åœºæ™¯ | ç›®æ ‡å»¶è¿Ÿ | ç¼“å†²åŒºå¤§å° | ä¼˜åŒ–ç­–ç•¥ | å®ç°éš¾åº¦ |
|---------|---------|------------|----------|----------|
| **å®æ—¶ç›‘å¬** | <5ms | 64-128 samples | æç®€å¤„ç†é“¾ | æé«˜ |
| **éŸ³ä¹åˆ¶ä½œ** | <10ms | 128-256 samples | ä¸“ä¸šä¼˜åŒ– | é«˜ |
| **æ¸¸æˆéŸ³æ•ˆ** | <20ms | 256-512 samples | å¹³è¡¡ä¼˜åŒ– | ä¸­ |
| **è¯­éŸ³é€šè¯** | <30ms | 512-1024 samples | ç¨³å®šä¼˜å…ˆ | ä½ |
| **éŸ³ä¹æ’­æ”¾** | <100ms | 1024-4096 samples | è´¨é‡ä¼˜å…ˆ | å¾ˆä½ |

### 2. æé™å»¶è¿Ÿä¼˜åŒ–æŠ€æœ¯

#### ç¡¬ä»¶çº§ä¼˜åŒ–é…ç½®

```c
// è¶…ä½å»¶è¿ŸAudioQueueé…ç½®
typedef struct {
    // ç¡¬ä»¶é…ç½®
    Float64                 optimalSampleRate;      // æœ€ä¼˜é‡‡æ ·ç‡
    UInt32                  minimalBufferSize;      // æœ€å°ç¼“å†²åŒº
    UInt32                  hardwareBufferSize;     // ç¡¬ä»¶ç¼“å†²åŒº
    
    // ç³»ç»Ÿä¼˜åŒ–
    Boolean                 disableAutomaticGainControl;  // ç¦ç”¨AGC
    Boolean                 disableEchoCancellation;      // ç¦ç”¨å›å£°æ¶ˆé™¤
    Boolean                 disableNoiseReduction;       // ç¦ç”¨é™å™ª
    Boolean                 enableRawMode;              // å¯ç”¨åŸå§‹æ¨¡å¼
    
    // çº¿ç¨‹ä¼˜åŒ–
    Boolean                 useRealtimeThread;          // ä½¿ç”¨å®æ—¶çº¿ç¨‹
    UInt32                  realtimePriority;           // å®æ—¶ä¼˜å…ˆçº§
    UInt32                  cpuAffinity;                // CPUäº²å’Œæ€§
    
    // å†…å­˜ä¼˜åŒ–
    Boolean                 lockMemoryPages;            // é”å®šå†…å­˜é¡µ
    Boolean                 useWiredMemory;             // ä½¿ç”¨æœ‰çº¿å†…å­˜
    UInt32                  memoryAlignment;            // å†…å­˜å¯¹é½
    
} UltraLowLatencyConfig;

// æé™å»¶è¿Ÿåˆå§‹åŒ–
OSStatus InitializeUltraLowLatencyAudioQueue(AudioQueueRef *outQueue,
                                            const UltraLowLatencyConfig *config) {
    OSStatus result = noErr;
    
    // 1. é…ç½®éŸ³é¢‘ä¼šè¯ä¸ºæä½å»¶è¿Ÿæ¨¡å¼
    AVAudioSession *session = [AVAudioSession sharedInstance];
    
    // è®¾ç½®æœ€æ¿€è¿›çš„éŸ³é¢‘é…ç½®
    NSError *error;
    [session setCategory:AVAudioSessionCategoryPlayAndRecord 
                    mode:AVAudioSessionModeMeasurement  // æµ‹é‡æ¨¡å¼ï¼Œæœ€ä½å»¶è¿Ÿ
                 options:AVAudioSessionCategoryOptionMixWithOthers |
                         AVAudioSessionCategoryOptionDefaultToSpeaker |
                         AVAudioSessionCategoryOptionInterruptSpokenAudioAndMixWithOthers
                   error:&error];
    
    // è®¾ç½®æå°çš„I/Oç¼“å†²åŒºæŒç»­æ—¶é—´
    Float64 targetDuration = 64.0 / config->optimalSampleRate; // ~1.45ms @ 44.1kHz
    [session setPreferredIOBufferDuration:targetDuration error:&error];
    
    // è®¾ç½®é‡‡æ ·ç‡
    [session setPreferredSampleRate:config->optimalSampleRate error:&error];
    
    // æ¿€æ´»ä¼šè¯
    [session setActive:YES error:&error];
    
    // 2. åˆ›å»ºè¶…ä½å»¶è¿ŸéŸ³é¢‘æ ¼å¼
    AudioStreamBasicDescription format;
    memset(&format, 0, sizeof(format));
    format.mSampleRate = config->optimalSampleRate;
    format.mFormatID = kAudioFormatLinearPCM;
    format.mFormatFlags = kAudioFormatFlagIsFloat | 
                         kAudioFormatFlagIsPacked | 
                         kAudioFormatFlagIsNonInterleaved;  // éäº¤é”™ï¼Œæ€§èƒ½æ›´å¥½
    format.mChannelsPerFrame = 2;
    format.mBitsPerChannel = 32;
    format.mBytesPerFrame = sizeof(Float32);
    format.mBytesPerPacket = format.mBytesPerFrame;
    format.mFramesPerPacket = 1;
    
    // 3. åˆ›å»ºéŸ³é¢‘é˜Ÿåˆ—
    result = AudioQueueNewOutput(&format,
                                UltraLowLatencyCallback,
                                config,
                                NULL,  // ä¸ä½¿ç”¨RunLoop
                                NULL,
                                0,
                                outQueue);
    if (result != noErr) return result;
    
    // 4. è®¾ç½®ç¡¬ä»¶ä¼˜åŒ–å±æ€§
    UInt32 enableLowLatency = 1;
    AudioQueueSetProperty(*outQueue,
                         kAudioQueueProperty_EnableLevelMetering,
                         &enableLowLatency,
                         sizeof(enableLowLatency));
    
    // 5. é…ç½®å®æ—¶çº¿ç¨‹
    if (config->useRealtimeThread) {
        ConfigureUltraRealtimeThread(*outQueue, config);
    }
    
    return noErr;
}

// è¶…ä½å»¶è¿Ÿå›è°ƒå‡½æ•°
void UltraLowLatencyCallback(void *userData,
                            AudioQueueRef audioQueue,
                            AudioQueueBufferRef buffer) {
    // æœ€å°åŒ–çš„å¤„ç† - æ¯ä¸€çº³ç§’éƒ½é‡è¦
    
    // é¿å…ä»»ä½•ç³»ç»Ÿè°ƒç”¨
    // é¿å…å†…å­˜åˆ†é…
    // é¿å…äº’æ–¥é”
    // é¿å…æ¡ä»¶å˜é‡
    
    UltraLowLatencyConfig *config = (UltraLowLatencyConfig *)userData;
    
    // åŸå­æ“ä½œè·å–æ•°æ®ï¼ˆé”æ— å…³ï¼‰
    Float32 *audioData = (Float32 *)buffer->mAudioData;
    UInt32 frameCount = buffer->mAudioDataBytesCapacity / sizeof(Float32) / 2;
    
    // æœ€ç®€å•çš„éŸ³é¢‘å¤„ç†ï¼ˆç¤ºä¾‹ï¼šç›´é€šï¼‰
    for (UInt32 frame = 0; frame < frameCount; frame++) {
        audioData[frame * 2] = 0.0f;     // å·¦å£°é“
        audioData[frame * 2 + 1] = 0.0f; // å³å£°é“
    }
    
    buffer->mAudioDataByteSize = buffer->mAudioDataBytesCapacity;
    
    // ç«‹å³å…¥é˜Ÿï¼Œé¿å…å»¶è¿Ÿ
    AudioQueueEnqueueBuffer(audioQueue, buffer, 0, NULL);
}
```

#### CPUå’Œçº¿ç¨‹æé™ä¼˜åŒ–

```c
// è¶…çº§å®æ—¶çº¿ç¨‹é…ç½®
OSStatus ConfigureUltraRealtimeThread(AudioQueueRef queue,
                                     const UltraLowLatencyConfig *config) {
    // è·å–éŸ³é¢‘çº¿ç¨‹
    mach_port_t audioThread = pthread_mach_thread_np(pthread_self());
    
    // è®¾ç½®æ—¶é—´çº¦æŸç­–ç•¥ - æœ€æ¿€è¿›çš„è®¾ç½®
    thread_time_constraint_policy_data_t policy;
    
    // åŸºäºé‡‡æ ·ç‡è®¡ç®—æœ€ç´§çš„æ—¶é—´çº¦æŸ
    UInt32 samplesPerCallback = config->minimalBufferSize;
    UInt64 periodNanos = (UInt64)((Float64)samplesPerCallback / config->optimalSampleRate * 1e9);
    
    policy.period = AudioConvertNanosToHostTime(periodNanos);
    policy.computation = policy.period / 2;  // 50%çš„æ—¶é—´ç”¨äºè®¡ç®—
    policy.constraint = policy.period;       // å¿…é¡»åœ¨å‘¨æœŸå†…å®Œæˆ
    policy.preemptible = FALSE;              // ä¸å¯æŠ¢å 
    
    kern_return_t kr = thread_policy_set(audioThread,
                                        THREAD_TIME_CONSTRAINT_POLICY,
                                        (thread_policy_t)&policy,
                                        THREAD_TIME_CONSTRAINT_POLICY_COUNT);
    
    if (kr != KERN_SUCCESS) {
        return kAudioQueueErr_InvalidRunState;
    }
    
    // è®¾ç½®çº¿ç¨‹äº²å’Œæ€§ - ç»‘å®šåˆ°æ€§èƒ½æ ¸å¿ƒ
    thread_affinity_policy_data_t affinityPolicy;
    affinityPolicy.affinity_tag = config->cpuAffinity;
    
    kr = thread_policy_set(audioThread,
                          THREAD_AFFINITY_POLICY,
                          (thread_policy_t)&affinityPolicy,
                          THREAD_AFFINITY_POLICY_COUNT);
    
    // è®¾ç½®çº¿ç¨‹ä¼˜å…ˆçº§ä¸ºæœ€é«˜
    struct sched_param param;
    param.sched_priority = sched_get_priority_max(SCHED_RR);
    pthread_setschedparam(pthread_self(), SCHED_RR, &param);
    
    return (kr == KERN_SUCCESS) ? noErr : kAudioQueueErr_InvalidRunState;
}

// å†…å­˜ä¼˜åŒ– - é¢„åˆ†é…å’Œé”å®š
OSStatus OptimizeMemoryForUltraLowLatency(AudioQueueRef queue,
                                         UInt32 bufferSize,
                                         UInt32 bufferCount) {
    // è®¡ç®—æ‰€éœ€å†…å­˜å¤§å°
    size_t totalMemorySize = bufferSize * bufferCount;
    
    // å¯¹é½åˆ°é¡µè¾¹ç•Œ
    size_t pageSize = getpagesize();
    totalMemorySize = (totalMemorySize + pageSize - 1) & ~(pageSize - 1);
    
    // åˆ†é…æœ‰çº¿å†…å­˜ï¼ˆä¸ä¼šè¢«äº¤æ¢åˆ°ç£ç›˜ï¼‰
    void *wiredMemory = valloc(totalMemorySize);
    if (!wiredMemory) {
        return kAudioQueueErr_MemoryFailure;
    }
    
    // é”å®šå†…å­˜é¡µé¢
    if (mlock(wiredMemory, totalMemorySize) != 0) {
        free(wiredMemory);
        return kAudioQueueErr_MemoryFailure;
    }
    
    // é¢„è§¦æ‘¸æ‰€æœ‰é¡µé¢ä»¥ç¡®ä¿å®ƒä»¬è¢«ç‰©ç†åˆ†é…
    volatile char *touch = (volatile char *)wiredMemory;
    for (size_t i = 0; i < totalMemorySize; i += pageSize) {
        touch[i] = 0;
    }
    
    return noErr;
}
```

#### ç³»ç»Ÿçº§æ€§èƒ½ç›‘æ§

```c
// å®æ—¶æ€§èƒ½ç›‘æ§å™¨
typedef struct {
    // å»¶è¿Ÿç»Ÿè®¡
    uint64_t    minLatency;         // æœ€å°å»¶è¿Ÿ
    uint64_t    maxLatency;         // æœ€å¤§å»¶è¿Ÿ
    uint64_t    avgLatency;         // å¹³å‡å»¶è¿Ÿ
    uint64_t    currentLatency;     // å½“å‰å»¶è¿Ÿ
    
    // æŠ–åŠ¨ç»Ÿè®¡
    uint64_t    minJitter;          // æœ€å°æŠ–åŠ¨
    uint64_t    maxJitter;          // æœ€å¤§æŠ–åŠ¨
    uint64_t    avgJitter;          // å¹³å‡æŠ–åŠ¨
    
    // æ€§èƒ½è®¡æ•°
    UInt64      totalCallbacks;     // æ€»å›è°ƒæ¬¡æ•°
    UInt64      missedDeadlines;    // é”™è¿‡æˆªæ­¢æ—¶é—´æ¬¡æ•°
    UInt64      bufferUnderruns;    // ç¼“å†²åŒºæ¬ è½½æ¬¡æ•°
    
    // ç³»ç»Ÿè´Ÿè½½
    Float32     cpuUsage;           // CPUä½¿ç”¨ç‡
    Float32     memoryPressure;     // å†…å­˜å‹åŠ›
    Float32     thermalState;       // çƒ­çŠ¶æ€
    
    // æ—¶é—´æˆ³
    uint64_t    lastCallbackTime;   // æœ€åå›è°ƒæ—¶é—´
    uint64_t    expectedInterval;   // æœŸæœ›é—´éš”
    
} RealtimePerformanceMonitor;

// æ€§èƒ½ç›‘æ§æ›´æ–°
void UpdateRealtimePerformanceMetrics(RealtimePerformanceMonitor *monitor,
                                     uint64_t callbackStartTime,
                                     uint64_t callbackEndTime) {
    // è®¡ç®—å½“å‰å»¶è¿Ÿ
    monitor->currentLatency = callbackEndTime - callbackStartTime;
    
    // æ›´æ–°å»¶è¿Ÿç»Ÿè®¡
    if (monitor->currentLatency < monitor->minLatency || monitor->minLatency == 0) {
        monitor->minLatency = monitor->currentLatency;
    }
    if (monitor->currentLatency > monitor->maxLatency) {
        monitor->maxLatency = monitor->currentLatency;
    }
    
    // è®¡ç®—ç§»åŠ¨å¹³å‡å»¶è¿Ÿ
    monitor->avgLatency = (monitor->avgLatency * 15 + monitor->currentLatency) / 16;
    
    // è®¡ç®—æŠ–åŠ¨
    if (monitor->lastCallbackTime > 0) {
        uint64_t actualInterval = callbackStartTime - monitor->lastCallbackTime;
        uint64_t jitter = (actualInterval > monitor->expectedInterval) ?
                         (actualInterval - monitor->expectedInterval) :
                         (monitor->expectedInterval - actualInterval);
        
        if (jitter < monitor->minJitter || monitor->minJitter == 0) {
            monitor->minJitter = jitter;
        }
        if (jitter > monitor->maxJitter) {
            monitor->maxJitter = jitter;
        }
        monitor->avgJitter = (monitor->avgJitter * 15 + jitter) / 16;
        
        // æ£€æŸ¥æ˜¯å¦é”™è¿‡æˆªæ­¢æ—¶é—´
        if (actualInterval > monitor->expectedInterval * 1.1) {
            monitor->missedDeadlines++;
        }
    }
    
    monitor->lastCallbackTime = callbackStartTime;
    monitor->totalCallbacks++;
    
    // ç³»ç»Ÿè´Ÿè½½ç›‘æ§ï¼ˆæ¯100æ¬¡å›è°ƒæ›´æ–°ä¸€æ¬¡ï¼‰
    if (monitor->totalCallbacks % 100 == 0) {
        UpdateSystemLoadMetrics(monitor);
    }
}

// æ€§èƒ½æŠ¥å‘Šç”Ÿæˆ
void GeneratePerformanceReport(const RealtimePerformanceMonitor *monitor,
                              char *reportBuffer,
                              size_t bufferSize) {
    Float64 minLatencyMs = AudioConvertHostTimeToNanos(monitor->minLatency) / 1e6;
    Float64 maxLatencyMs = AudioConvertHostTimeToNanos(monitor->maxLatency) / 1e6;
    Float64 avgLatencyMs = AudioConvertHostTimeToNanos(monitor->avgLatency) / 1e6;
    Float64 maxJitterMs = AudioConvertHostTimeToNanos(monitor->maxJitter) / 1e6;
    
    snprintf(reportBuffer, bufferSize,
             "=== å®æ—¶éŸ³é¢‘æ€§èƒ½æŠ¥å‘Š ===\n"
             "å»¶è¿Ÿç»Ÿè®¡:\n"
             "  æœ€å°: %.3f ms\n"
             "  æœ€å¤§: %.3f ms\n"
             "  å¹³å‡: %.3f ms\n"
             "æŠ–åŠ¨ç»Ÿè®¡:\n"
             "  æœ€å¤§: %.3f ms\n"
             "æ€§èƒ½æŒ‡æ ‡:\n"
             "  æ€»å›è°ƒ: %llu\n"
             "  é”™è¿‡æˆªæ­¢æ—¶é—´: %llu (%.2f%%)\n"
             "  ç¼“å†²åŒºæ¬ è½½: %llu\n"
             "ç³»ç»Ÿè´Ÿè½½:\n"
             "  CPUä½¿ç”¨ç‡: %.1f%%\n"
             "  å†…å­˜å‹åŠ›: %.1f%%\n",
             minLatencyMs, maxLatencyMs, avgLatencyMs,
             maxJitterMs,
             monitor->totalCallbacks,
             monitor->missedDeadlines,
             (Float64)monitor->missedDeadlines / monitor->totalCallbacks * 100.0,
             monitor->bufferUnderruns,
             monitor->cpuUsage * 100.0,
             monitor->memoryPressure * 100.0);
}
```

### 2. æœ€ä½³å®è·µä¸é«˜çº§æŠ€å·§

#### é”™è¯¯å¤„ç†ä¸æ¢å¤

```c
// æ™ºèƒ½é”™è¯¯æ¢å¤ç³»ç»Ÿ
typedef struct AudioErrorRecovery {
    UInt32 errorCount[10];  // é”™è¯¯è®¡æ•°å™¨
    CFAbsoluteTime lastErrorTime;
    UInt32 recoveryAttempts;
    AudioQueueRef backupQueue;  // å¤‡ç”¨é˜Ÿåˆ—
} AudioErrorRecovery;

OSStatus HandleAudioQueueError(OSStatus error, 
                               AudioQueueRef queue,
                               AudioErrorRecovery *recovery) {
    // è®°å½•é”™è¯¯
    UInt32 errorIndex = (UInt32)error % 10;
    recovery->errorCount[errorIndex]++;
    recovery->lastErrorTime = CFAbsoluteTimeGetCurrent();
    
    switch (error) {
        case kAudioQueueErr_BufferEmpty:
            return RecoverFromBufferEmpty(queue);
            
        case kAudioQueueErr_InvalidBuffer:
            return RecoverFromInvalidBuffer(queue);
            
        case kAudioQueueErr_InvalidProperty:
            return RecoverFromInvalidProperty(queue);
            
        default:
            if (recovery->recoveryAttempts < 3) {
                recovery->recoveryAttempts++;
                return RestartAudioQueue(queue, recovery);
            } else {
                return error;
            }
    }
}
```

## æ€»ç»“ä¸æŠ€æœ¯å±•æœ›

### AudioQueue æŠ€æœ¯ä¼˜åŠ¿æ€»ç»“

```mermaid
mindmap
  root)AudioQueueæ ¸å¿ƒä¼˜åŠ¿(
    æ€§èƒ½ä¼˜åŒ–
      åº•æ—¶å»¶å¤„ç†
      ç›´æ¥ç¡¬ä»¶è®¿é—®
      ç²¾ç¡®ç¼“å†²æ§åˆ¶
      å®æ—¶çº¿ç¨‹ä¼˜åŒ–
    å¼€å‘ä¾¿åˆ©
      Cè¯­è¨€API
      è·¨å¹³å°æ”¯æŒ
      ä¸°å¯Œæ–‡æ¡£
      æˆç†Ÿç¨³å®š
    åº”ç”¨å¹¿æ³›
      ä¸“ä¸šéŸ³é¢‘
      æ¸¸æˆå¼€å‘
      å®æ—¶é€šè®¯
      éŸ³é¢‘åˆ†æ
    æ‰©å±•æ€§å¼º
      ä¸AudioUnité›†æˆ
      è‡ªå®šä¹‰å¤„ç†
      æ’ä»¶æ¶æ„
      æ¨¡å—åŒ–è®¾è®¡
    
    %%{init: {'theme': 'base', 'themeVariables': {'primaryColor': '#e3f2fd', 'primaryTextColor': '#000', 'primaryBorderColor': '#1976d2', 'lineColor': '#1976d2', 'tertiaryColor': '#e8f5e8', 'background': '#ffffff', 'secondaryColor': '#f5f5f5', 'tertiaryTextColor': '#000'}}}%%
```

### æ€§èƒ½å¯¹æ¯”åˆ†æ

| ç‰¹æ€§å¯¹æ¯” | AVFoundation | AudioQueue | AudioUnit |
|---------|-------------|------------|-----------|
| å¼€å‘å¤æ‚åº¦ | ä½ | ä¸­ | é«˜ |
| æ€§èƒ½è¡¨ç° | ä¸­ | é«˜ | æœ€é«˜ |
| åº•æ—¶å»¶èƒ½åŠ› | 10-50ms | 2-10ms | <2ms |
| å†…å­˜æ§åˆ¶ | è‡ªåŠ¨ | æ‰‹åŠ¨ | å®Œå…¨æ‰‹åŠ¨ |
| è·¨å¹³å°æ€§ | iOS/macOS | å…¨å¹³å° | å…¨å¹³å° |
| å­¦ä¹ æ›²çº¿ | å¹³ç¼“ | ä¸­ç­‰ | é™¡å³­ |

### åº”ç”¨åœºæ™¯æŒ‡å—

**AudioQueue æœ€ä½³é€‚ç”¨åœºæ™¯**ï¼š
1. **ä¸“ä¸šéŸ³é¢‘åº”ç”¨**ï¼šéœ€è¦ç²¾ç¡®å»¶è¿Ÿæ§åˆ¶çš„å½•éŸ³ã€æ··éŸ³è½¯ä»¶
2. **æ¸¸æˆéŸ³é¢‘å¼•æ“**ï¼šå®æ—¶éŸ³æ•ˆå¤„ç†å’Œ3DéŸ³é¢‘å®šä½
3. **å®æ—¶é€šè®¯**ï¼šVoIPã€ç›´æ’­ç­‰éœ€è¦ä½å»¶è¿Ÿçš„åº”ç”¨
4. **éŸ³é¢‘åˆ†æå·¥å…·**ï¼šé¢‘è°±åˆ†æã€éŸ³é¢‘æµ‹é‡ç­‰ä¸“ä¸šå·¥å…·
5. **æ•™è‚²å’Œç ”ç©¶**ï¼šéŸ³é¢‘ç®—æ³•éªŒè¯å’Œæ€§èƒ½æµ‹è¯•

### æœªæ¥å‘å±•è¶‹åŠ¿

**æŠ€æœ¯å‘å±•æ–¹å‘**ï¼š
1. **AIé›†æˆ**ï¼šæœºå™¨å­¦ä¹ éŸ³é¢‘å¤„ç†ç®—æ³•çš„åŸç”Ÿæ”¯æŒ
2. **ç¡¬ä»¶åŠ é€Ÿ**ï¼šæ›´æ·±åº¦çš„ä¸“ç”¨éŸ³é¢‘èŠ¯ç‰‡é›†æˆ
3. **å»¶è¿Ÿä¼˜åŒ–**ï¼šæ¥è¿‘ç¡¬ä»¶æé™çš„è¶…ä½å»¶è¿Ÿå¤„ç†
4. **äº‘ç«¯åä½œ**ï¼šæœ¬åœ°ä¸äº‘ç«¯éŸ³é¢‘å¤„ç†çš„æ— ç¼ç»“åˆ

**æœ€ä½³å®è·µå»ºè®®**ï¼š
1. **æ·±å…¥ç†è§£åŸç†**ï¼šæŒæ¡AudioQueueçš„å†…éƒ¨å·¥ä½œæœºåˆ¶
2. **æ€§èƒ½ä¼˜å…ˆè®¾è®¡**ï¼šåœ¨æ¶æ„è®¾è®¡é˜¶æ®µå°±è€ƒè™‘æ€§èƒ½ä¼˜åŒ–
3. **å®Œå–„é”™è¯¯å¤„ç†**ï¼šå»ºç«‹å¥å£®çš„é”™è¯¯æ¢å¤æœºåˆ¶
4. **æŒç»­æ€§èƒ½ç›‘æ§**ï¼šå®æ—¶ç›‘æ§å’Œè°ƒä¼˜éŸ³é¢‘æ€§èƒ½
5. **è·¨å¹³å°è€ƒè™‘**ï¼šä¸ºæœªæ¥çš„å¹³å°æ‰©å±•åšå¥½å‡†å¤‡

AudioQueue ä½œä¸ºCore Audioçš„æ ¸å¿ƒç»„ä»¶ï¼Œä¸ºå¼€å‘è€…æä¾›äº†åœ¨æ€§èƒ½å’Œæ˜“ç”¨æ€§ä¹‹é—´çš„å®Œç¾å¹³è¡¡ã€‚é€šè¿‡æ·±å…¥ç†è§£å…¶å·¥ä½œåŸç†å’Œæœ€ä½³å®è·µï¼Œå¼€å‘è€…å¯ä»¥æ„å»ºå‡ºé«˜æ€§èƒ½ã€ä½å»¶è¿Ÿçš„ä¸“ä¸šçº§éŸ³é¢‘åº”ç”¨ã€‚
```
